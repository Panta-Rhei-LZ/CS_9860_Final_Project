{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlparse\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, TRANSFORMERS_CACHE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "17170956288\n",
      "C:\\Users\\zly20\\.cache\\huggingface\\hub\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "available_memory = torch.cuda.get_device_properties(0).total_memory\n",
    "print(available_memory)\n",
    "\n",
    "print(TRANSFORMERS_CACHE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b60eebced325466dbf653b1c52abcc0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:  88%|########7 | 3.12G/3.55G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\huggingface_hub\\file_download.py:140: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in E:\\Data File\\transformers.cache\\models--deepseek-ai--DeepSeek-R1-Distill-Qwen-1.5B. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0446e570b2474520860cb323d678dee3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/181 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name = \"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\"\n",
    "cache_dir = \"E:/Data File/transformers.cache\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name,cache_dir=cache_dir)\n",
    "\n",
    "if available_memory > 15e9:\n",
    "    # if you have atleast 15GB of GPU memory, run load the model in float16\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_name,\n",
    "        trust_remote_code=True,\n",
    "        torch_dtype=torch.float16,\n",
    "        device_map=\"auto\",\n",
    "        use_cache=True,\n",
    "        cache_dir=cache_dir\n",
    "    )\n",
    "else:\n",
    "    # else, load in 8 bits – this is a bit slower\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_name,\n",
    "        trust_remote_code=True,\n",
    "        # torch_dtype=torch.float16,\n",
    "        load_in_8bit=True,\n",
    "        device_map=\"auto\",\n",
    "        use_cache=True,\n",
    "        cache_dir=cache_dir\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"### Task\n",
    "Generate a SQL query to answer [QUESTION]{question}[/QUESTION]\n",
    "\n",
    "### Instructions\n",
    "- If you cannot answer the question with the available database schema, return 'I do not know'\n",
    "- You do not need to generate your thought process but just the answer\n",
    "\n",
    "For example:\n",
    "  question: 'List all the businesses with more than 4.5 stars',\n",
    "  answer: 'SELECT name FROM business WHERE rating > 4.5'\n",
    "\n",
    "### Database Schema\n",
    "This query will run on a database whose schema is represented in this string:\n",
    "CREATE TABLE business (\n",
    "  bid INTEGER PRIMARY KEY AUTO_INCREMENT, -- Unique ID for each business\n",
    "  business_id VARCHAR(255) NOT NULL UNIQUE, -- External business identifier\n",
    "  name VARCHAR(255) NOT NULL, -- Name of the business\n",
    "  full_address VARCHAR(255) NOT NULL, -- Full street address\n",
    "  city VARCHAR(255) NOT NULL, -- City of the business\n",
    "  latitude VARCHAR(255) NOT NULL, -- Latitude coordinate\n",
    "  longitude VARCHAR(255) NOT NULL, -- Longitude coordinate\n",
    "  review_count BIGINT NOT NULL, -- Number of reviews the business has received\n",
    "  is_open TINYINT(1) NOT NULL, -- Indicates if the business is open (1) or closed (0)\n",
    "  rating FLOAT DEFAULT NULL, -- Average rating of the business\n",
    "  state VARCHAR(255) DEFAULT NULL -- State or province\n",
    ");\n",
    "\n",
    "CREATE TABLE category (\n",
    "  id INTEGER PRIMARY KEY AUTO_INCREMENT, -- Unique ID for each category record\n",
    "  business_id VARCHAR(255) NOT NULL, -- ID of the business this category belongs to\n",
    "  category_name VARCHAR(255) NOT NULL, -- Name of the category\n",
    "  FOREIGN KEY (business_id) REFERENCES business(business_id)\n",
    ");\n",
    "\n",
    "CREATE TABLE checkin (\n",
    "  cid INTEGER PRIMARY KEY AUTO_INCREMENT, -- Unique ID for each check-in record\n",
    "  business_id VARCHAR(255) NOT NULL, -- ID of the business where the check-in occurred\n",
    "  count INTEGER DEFAULT NULL, -- Number of check-ins\n",
    "  day VARCHAR(12) DEFAULT NULL, -- Day of the week the check-in occurred\n",
    "  FOREIGN KEY (business_id) REFERENCES business(business_id)\n",
    ");\n",
    "\n",
    "CREATE TABLE neighborhood (\n",
    "  id INTEGER PRIMARY KEY AUTO_INCREMENT, -- Unique ID for each neighborhood record\n",
    "  business_id VARCHAR(255) NOT NULL, -- ID of the business in the neighborhood\n",
    "  neighborhood_name VARCHAR(255) NOT NULL, -- Name of the neighborhood\n",
    "  FOREIGN KEY (business_id) REFERENCES business(business_id)\n",
    ");\n",
    "\n",
    "CREATE TABLE review (\n",
    "  rid INTEGER PRIMARY KEY AUTO_INCREMENT, -- Unique ID for each review\n",
    "  business_id VARCHAR(255) NOT NULL, -- ID of the business being reviewed\n",
    "  user_id VARCHAR(255) NOT NULL, -- ID of the user who wrote the review\n",
    "  rating FLOAT DEFAULT NULL, -- Rating given in the review\n",
    "  text LONGTEXT NOT NULL, -- Content of the review\n",
    "  year INTEGER DEFAULT NULL, -- Year the review was posted\n",
    "  month VARCHAR(10) DEFAULT NULL, -- Month the review was posted\n",
    "  FOREIGN KEY (business_id) REFERENCES business(business_id),\n",
    "  FOREIGN KEY (user_id) REFERENCES user(user_id)\n",
    ");\n",
    "\n",
    "CREATE TABLE tip (\n",
    "  tip_id INTEGER PRIMARY KEY AUTO_INCREMENT, -- Unique ID for each tip\n",
    "  business_id VARCHAR(255) NOT NULL, -- ID of the business the tip is about\n",
    "  text LONGTEXT NOT NULL, -- Content of the tip\n",
    "  user_id VARCHAR(255) NOT NULL, -- ID of the user who left the tip\n",
    "  likes INTEGER NOT NULL, -- Number of likes the tip received\n",
    "  year INTEGER DEFAULT NULL, -- Year the tip was posted\n",
    "  month VARCHAR(10) DEFAULT NULL, -- Month the tip was posted\n",
    "  FOREIGN KEY (business_id) REFERENCES business(business_id),\n",
    "  FOREIGN KEY (user_id) REFERENCES user(user_id)\n",
    ");\n",
    "\n",
    "CREATE TABLE user (\n",
    "  uid INTEGER PRIMARY KEY AUTO_INCREMENT, -- Unique ID for each user record\n",
    "  user_id VARCHAR(255) NOT NULL UNIQUE, -- External user identifier\n",
    "  name VARCHAR(255) NOT NULL -- Name of the user\n",
    ");\n",
    "\n",
    "### Answer\n",
    "Given the database schema, here is the SQL query that answers [QUESTION]{question}[/QUESTION]\n",
    "[SQL]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_query(question):\n",
    "    updated_prompt = prompt.format(question=question)\n",
    "    inputs = tokenizer(updated_prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "    generated_ids = model.generate(\n",
    "        **inputs,\n",
    "        num_return_sequences=1,\n",
    "        eos_token_id=tokenizer.eos_token_id,\n",
    "        pad_token_id=tokenizer.eos_token_id,\n",
    "        max_new_tokens=512,\n",
    "        do_sample=False,\n",
    "        num_beams=1,\n",
    "    )\n",
    "    outputs = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    torch.cuda.synchronize()\n",
    "    # empty cache so that you do generate more results w/o memory crashing\n",
    "    # particularly important on Colab – memory management is much more straightforward\n",
    "    # when running on an inference service\n",
    "    return sqlparse.format(outputs[0].split(\"[SQL]\")[1].split(\"[/SQL]\")[0], reindent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SELECT r.name\n",
      "FROM review r\n",
      "WHERE r.rating > 3.5\n"
     ]
    }
   ],
   "source": [
    "question = \"List all the restaurant rated more than 3.5\"\n",
    "generated_sql = generate_query(question)\n",
    "print(generated_sql)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
