{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "department_prompt = \"\"\"\n",
    "### Task\n",
    "Generate a SQLite query to answer [QUESTION]{question}[/QUESTION]\n",
    "\n",
    "### Instructions\n",
    "- If you cannot answer the question with the available database schema, return 'I do not know'\n",
    "- Pay close attention to the given database schema, note on how they can join together\n",
    "- You do not need to generate your thought process but just the answer\n",
    "- Your answer should end with '[/SQL]'\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS \"department\" (\n",
    "\"Department_ID\" int,\n",
    "\"Name\" text,\n",
    "\"Creation\" text,\n",
    "\"Ranking\" int,\n",
    "\"Budget_in_Billions\" real,\n",
    "\"Num_Employees\" real,\n",
    "PRIMARY KEY (\"Department_ID\")\n",
    ");\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS \"head\" (\n",
    "\"head_ID\" int,\n",
    "\"name\" text,\n",
    "\"born_state\" text,\n",
    "\"age\" real,\n",
    "PRIMARY KEY (\"head_ID\")\n",
    ");\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS \"management\" (\n",
    "\"department_ID\" int,\n",
    "\"head_ID\" int,\n",
    "\"temporary_acting\" text,\n",
    "PRIMARY KEY (\"Department_ID\",\"head_ID\"),\n",
    "FOREIGN KEY (\"Department_ID\") REFERENCES `department`(\"Department_ID\"),\n",
    "FOREIGN KEY (\"head_ID\") REFERENCES `head`(\"head_ID\")\n",
    ");\n",
    "\n",
    "### Answer\n",
    "Given the database schema, here is the SQLite query that answers [QUESTION]{question}[/QUESTION]\n",
    "[SQL]\n",
    "\"\"\" \n",
    "\n",
    "\n",
    "farm_prompt = \"\"\"\n",
    "### Task\n",
    "Generate a SQLite query to answer [QUESTION]{question}[/QUESTION]\n",
    "\n",
    "### Instructions\n",
    "- If you cannot answer the question with the available database schema, return 'I do not know'\n",
    "- Pay close attention to the given database schema, note on how they can join together\n",
    "- You do not need to generate your thought process but just the answer\n",
    "- Your answer should end with '[/SQL]'\n",
    "\n",
    "CREATE TABLE \"city\" (\n",
    "\"City_ID\" int,\n",
    "\"Official_Name\" text,\n",
    "\"Status\" text,\n",
    "\"Area_km_2\" real,\n",
    "\"Population\" real,\n",
    "\"Census_Ranking\" text,\n",
    "PRIMARY KEY (\"City_ID\")\n",
    ");\n",
    "\n",
    "CREATE TABLE \"farm\" (\n",
    "\"Farm_ID\" int,\n",
    "\"Year\" int,\n",
    "\"Total_Horses\" real,\n",
    "\"Working_Horses\" real,\n",
    "\"Total_Cattle\" real,\n",
    "\"Oxen\" real,\n",
    "\"Bulls\" real,\n",
    "\"Cows\" real,\n",
    "\"Pigs\" real,\n",
    "\"Sheep_and_Goats\" real,\n",
    "PRIMARY KEY (\"Farm_ID\")\n",
    ");\n",
    "\n",
    "CREATE TABLE \"farm_competition\" (\n",
    "\"Competition_ID\" int,\n",
    "\"Year\" int,\n",
    "\"Theme\" text,\n",
    "\"Host_city_ID\" int,\n",
    "\"Hosts\" text,\n",
    "PRIMARY KEY (\"Competition_ID\"),\n",
    "FOREIGN KEY (`Host_city_ID`) REFERENCES `city`(`City_ID`)\n",
    ");\n",
    "\n",
    "\n",
    "CREATE TABLE \"competition_record\" (\n",
    "\"Competition_ID\" int,\n",
    "\"Farm_ID\" int,\n",
    "\"Rank\" int,\n",
    "PRIMARY KEY (\"Competition_ID\",\"Farm_ID\"),\n",
    "FOREIGN KEY (`Competition_ID`) REFERENCES `farm_competition`(`Competition_ID`),\n",
    "FOREIGN KEY (`Farm_ID`) REFERENCES `farm`(`Farm_ID`)\n",
    ");\n",
    "\n",
    "### Answer\n",
    "Given the database schema, here is the SQLite query that answers [QUESTION]{question}[/QUESTION]\n",
    "[SQL]\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "aircraft_prompt = \"\"\"\n",
    "### Task\n",
    "Generate a SQLite query to answer [QUESTION]{question}[/QUESTION]\n",
    "\n",
    "### Instructions\n",
    "- If you cannot answer the question with the available database schema, return 'I do not know'\n",
    "- Pay close attention to the given database schema, note on how they can join together\n",
    "- You do not need to generate your thought process but just the answer\n",
    "- Your answer should end with '[/SQL]'\n",
    "\n",
    "CREATE TABLE `pilot` (\n",
    "  `Pilot_Id` int(11) NOT NULL,\n",
    "  `Name` varchar(50) NOT NULL,\n",
    "  `Age` int(11) NOT NULL,\n",
    "  PRIMARY KEY (`Pilot_Id`)\n",
    ");\n",
    "\n",
    "CREATE TABLE `aircraft` (\n",
    "  \"Aircraft_ID\" int(11) NOT NULL,\n",
    "  \"Aircraft\" varchar(50) NOT NULL,\n",
    "  \"Description\" varchar(50) NOT NULL,\n",
    "  \"Max_Gross_Weight\" varchar(50) NOT NULL,\n",
    "  \"Total_disk_area\" varchar(50) NOT NULL,\n",
    "  \"Max_disk_Loading\" varchar(50) NOT NULL,\n",
    "  PRIMARY KEY (`Aircraft_ID`)\n",
    ");\n",
    "\n",
    "CREATE TABLE `match` (\n",
    "\"Round\" real,\n",
    "\"Location\" text,\n",
    "\"Country\" text,\n",
    "\"Date\" text,\n",
    "\"Fastest_Qualifying\" text,\n",
    "\"Winning_Pilot\" text,\n",
    "\"Winning_Aircraft\" text,\n",
    "PRIMARY KEY (\"Round\"),\n",
    "FOREIGN KEY (`Winning_Aircraft`) REFERENCES `aircraft`(`Aircraft_ID`),\n",
    "FOREIGN KEY (`Winning_Pilot`) REFERENCES `pilot`(`Pilot_Id`)\n",
    ");\n",
    "\n",
    "CREATE TABLE `airport` (\n",
    "\"Airport_ID\" int,\n",
    "\"Airport_Name\" text,\n",
    "\"Total_Passengers\" real,\n",
    "\"%_Change_2007\" text,\n",
    "\"International_Passengers\" real,\n",
    "\"Domestic_Passengers\" real,\n",
    "\"Transit_Passengers\" real,\n",
    "\"Aircraft_Movements\" real,\n",
    "\"Freight_Metric_Tonnes\" real,\n",
    "PRIMARY KEY (\"Airport_ID\")\n",
    ");\n",
    "\n",
    "CREATE TABLE `airport_aircraft` (\n",
    "\"ID\" int,\n",
    "\"Airport_ID\" int,\n",
    "\"Aircraft_ID\" int,\n",
    "PRIMARY KEY (\"Airport_ID\",\"Aircraft_ID\"),\n",
    "FOREIGN KEY (\"Airport_ID\") REFERENCES `airport`(`Airport_ID`),\n",
    "FOREIGN KEY (\"Aircraft_ID\") REFERENCES `aircraft`(`Aircraft_ID`)\n",
    ");\n",
    "\n",
    "### Answer\n",
    "Given the database schema, here is the SQLite query that answers [QUESTION]{question}[/QUESTION]\n",
    "[SQL]\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "architecture_prompt = \"\"\"\n",
    "### Task\n",
    "Generate a SQLite query to answer [QUESTION]{question}[/QUESTION]\n",
    "\n",
    "### Instructions\n",
    "- If you cannot answer the question with the available database schema, return 'I do not know'\n",
    "- Pay close attention to the given database schema, note on how they can join together\n",
    "- You do not need to generate your thought process but just the answer\n",
    "- Your answer should end with '[/SQL]'\n",
    "\n",
    "CREATE TABLE \"architect\" (\n",
    "\"id\" text,\n",
    "\"name\" text,\n",
    "\"nationality\" text,\n",
    "\"gender\" text,\n",
    "primary key(\"id\")\n",
    ");\n",
    "\n",
    "CREATE TABLE \"bridge\" (\n",
    "\"architect_id\" int,\n",
    "\"id\" int,\n",
    "\"name\" text,\n",
    "\"location\" text,\n",
    "\"length_meters\" real,\n",
    "\"length_feet\" real,\n",
    "primary key(\"id\"),\n",
    "foreign key (\"architect_id\" ) references `architect`(\"id\")\n",
    ");\n",
    "\n",
    "CREATE TABLE \"mill\" (\n",
    "\"architect_id\" int,\n",
    "\"id\" int,\n",
    "\"location\" text,\n",
    "\"name\" text,\n",
    "\"type\" text,\n",
    "\"built_year\" int,\n",
    "\"notes\" text,\n",
    "primary key (\"id\"),\n",
    "foreign key (\"architect_id\" ) references `architect`(\"id\")\n",
    ");\n",
    "\n",
    "### Answer\n",
    "Given the database schema, here is the SQLite query that answers [QUESTION]{question}[/QUESTION]\n",
    "[SQL]\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "cinema_prompt = \"\"\"\n",
    "### Task\n",
    "Generate a SQLite query to answer [QUESTION]{question}[/QUESTION]\n",
    "\n",
    "### Instructions\n",
    "- If you cannot answer the question with the available database schema, return 'I do not know'\n",
    "- Pay close attention to the given database schema, note on how they can join together\n",
    "- You do not need to generate your thought process but just the answer\n",
    "- Your answer should end with '[/SQL]'\n",
    "\n",
    "CREATE TABLE \"film\" (\n",
    "\"Film_ID\" int,\n",
    "\"Rank_in_series\" int,\n",
    "\"Number_in_season\" int,\n",
    "\"Title\" text,\n",
    "\"Directed_by\" text,\n",
    "\"Original_air_date\" text,\n",
    "\"Production_code\" text,\n",
    "PRIMARY KEY (\"Film_ID\")\n",
    ");\n",
    "\n",
    "CREATE TABLE \"cinema\" (\n",
    "\"Cinema_ID\" int,\n",
    "\"Name\" text,\n",
    "\"Openning_year\" int,\n",
    "\"Capacity\" int,\n",
    "\"Location\" text,\n",
    "PRIMARY KEY (\"Cinema_ID\"));\n",
    "\n",
    "CREATE TABLE \"schedule\" (\n",
    "\"Cinema_ID\" int,\n",
    "\"Film_ID\" int,\n",
    "\"Date\" text,\n",
    "\"Show_times_per_day\" int,\n",
    "\"Price\" float,\n",
    "PRIMARY KEY (\"Cinema_ID\",\"Film_ID\"),\n",
    "FOREIGN KEY (`Film_ID`) REFERENCES `film`(`Film_ID`),\n",
    "FOREIGN KEY (`Cinema_ID`) REFERENCES `cinema`(`Cinema_ID`)\n",
    ");\n",
    "\n",
    "### Answer\n",
    "Given the database schema, here is the SQLite query that answers [QUESTION]{question}[/QUESTION]\n",
    "[SQL]\n",
    "\"\"\"\n",
    "\n",
    "# Store each prompt and its corresponding DB name\n",
    "dbs = [\n",
    "    (\"department_management\", department_prompt),\n",
    "    (\"farm\", farm_prompt),\n",
    "    (\"aircraft\", aircraft_prompt),\n",
    "    (\"architecture\", architecture_prompt),\n",
    "    (\"cinema\", cinema_prompt),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Data\n",
    "\n",
    "* Spider Dataset\n",
    "\n",
    "* https://yale-lily.github.io/spider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Saved 110 training and 39 test samples.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from datasets import load_dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load Spider dataset\n",
    "ds = load_dataset(\"spider\")\n",
    "db_ids = [x[0] for x in dbs]\n",
    "\n",
    "# Create a mapping for easy access to the prompt\n",
    "prompt_map = {db_id: prompt for db_id, prompt in dbs}\n",
    "\n",
    "train_data = []\n",
    "test_data = []\n",
    "\n",
    "for db_id in db_ids:\n",
    "    subset = ds[\"train\"].filter(lambda x: x[\"db_id\"] == db_id)\n",
    "    questions = [entry[\"question\"] for entry in subset]\n",
    "    queries = [entry[\"query\"] for entry in subset]\n",
    "\n",
    "    entries = [{\"db_id\": db_id, \"question\": q, \"query\": sql} for q, sql in zip(questions, queries)]\n",
    "\n",
    "    # Split 75% train, 25% test\n",
    "    train_split, test_split = train_test_split(entries, test_size=0.25, random_state=42)\n",
    "\n",
    "    train_data.extend(train_split)\n",
    "    test_data.extend(test_split)\n",
    "\n",
    "# Format prompt with input-output pairs\n",
    "def format_training_example(entry):\n",
    "    prompt_template = prompt_map[entry[\"db_id\"]]\n",
    "    prompt = prompt_template.format(question=entry[\"question\"])\n",
    "    return {\n",
    "        \"prompt\": prompt,\n",
    "        \"completion\": entry[\"query\"] + \" [/SQL]\"\n",
    "    }\n",
    "\n",
    "# Apply formatting\n",
    "train_formatted = [format_training_example(e) for e in train_data]\n",
    "test_formatted = [format_training_example(e) for e in test_data]\n",
    "\n",
    "# Save to JSON\n",
    "with open(\"train_formatted.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(train_formatted, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "with open(\"test_formatted.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(test_formatted, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"âœ… Saved {len(train_formatted)} training and {len(test_formatted)} test samples.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 2,179,072 || all params: 1,779,267,072 || trainable%: 0.1225\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc41e5c6da2d4cdc9d0376b0c87a0f9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "397a5d0db6dd4b45a4021ba236f1f21f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce1d492187454de0a9c0fae3eaeb6137",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/110 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa9d5bc0216f4ed0ac1badb6da98fe4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/39 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "from peft import prepare_model_for_kbit_training, LoraConfig, get_peft_model\n",
    "import torch\n",
    "\n",
    "model_name = \"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\"\n",
    "cache_dir = \"E:/Data File/transformers.cache\"\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.float16\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, cache_dir=cache_dir, trust_remote_code=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    device_map=\"auto\",\n",
    "    quantization_config=bnb_config,\n",
    "    cache_dir=cache_dir,\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "model = prepare_model_for_kbit_training(model)\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\"\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, lora_config)\n",
    "model.print_trainable_parameters()\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "data_files = {\n",
    "    \"train\": \"train_formatted.json\",\n",
    "    \"test\": \"test_formatted.json\"\n",
    "}\n",
    "\n",
    "dataset = load_dataset(\"json\", data_files=data_files)\n",
    "\n",
    "def tokenize(batch):\n",
    "    return tokenizer(\n",
    "        batch[\"prompt\"],\n",
    "        text_pair=batch[\"completion\"],\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=512,\n",
    "        return_tensors=None\n",
    "    )\n",
    "\n",
    "tokenized = dataset.map(tokenize, batched=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\_dynamo\\eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='266' max='1400' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 266/1400 05:21 < 23:02, 0.82 it/s, Epoch 19/100]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.302300</td>\n",
       "      <td>1.855368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.833500</td>\n",
       "      <td>1.379967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.124000</td>\n",
       "      <td>0.876066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.789700</td>\n",
       "      <td>0.550322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.416700</td>\n",
       "      <td>0.364381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.319700</td>\n",
       "      <td>0.262835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.234700</td>\n",
       "      <td>0.212509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.176200</td>\n",
       "      <td>0.189252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.151400</td>\n",
       "      <td>0.177137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.133400</td>\n",
       "      <td>0.168714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.128700</td>\n",
       "      <td>0.167193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.115100</td>\n",
       "      <td>0.159769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.110700</td>\n",
       "      <td>0.158152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.097400</td>\n",
       "      <td>0.153788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.100100</td>\n",
       "      <td>0.152768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.085200</td>\n",
       "      <td>0.151272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.088700</td>\n",
       "      <td>0.155991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.080800</td>\n",
       "      <td>0.156487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.068500</td>\n",
       "      <td>0.158307</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\_dynamo\\eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\_dynamo\\eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\_dynamo\\eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\_dynamo\\eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\_dynamo\\eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\_dynamo\\eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\_dynamo\\eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\_dynamo\\eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\_dynamo\\eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\_dynamo\\eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\_dynamo\\eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\_dynamo\\eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\_dynamo\\eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\_dynamo\\eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\_dynamo\\eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\_dynamo\\eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\_dynamo\\eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\_dynamo\\eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=266, training_loss=0.41547111304182754, metrics={'train_runtime': 323.178, 'train_samples_per_second': 34.037, 'train_steps_per_second': 4.332, 'total_flos': 9925377502740480.0, 'train_loss': 0.41547111304182754, 'epoch': 19.0})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import TrainingArguments, Trainer, DataCollatorForLanguageModeling\n",
    "from transformers import TrainerCallback\n",
    "from transformers import EarlyStoppingCallback\n",
    "\n",
    "class LossLoggerCallback(TrainerCallback):\n",
    "    def __init__(self):\n",
    "        self.train_logs = []\n",
    "        self.eval_logs = []\n",
    "\n",
    "    def on_log(self, args, state, control, logs=None, **kwargs):\n",
    "        if logs:\n",
    "            if \"loss\" in logs:\n",
    "                self.train_logs.append((state.epoch, logs[\"loss\"]))\n",
    "            if \"eval_loss\" in logs:\n",
    "                self.eval_logs.append((state.epoch, logs[\"eval_loss\"]))\n",
    "\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./lora-deepseek-1.5b\",\n",
    "    per_device_train_batch_size=4,\n",
    "    gradient_accumulation_steps=2,\n",
    "    num_train_epochs=100,\n",
    "    learning_rate=2e-4,\n",
    "    fp16=True,\n",
    "    logging_steps=10,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    "    greater_is_better=False,\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "loss_logger = LossLoggerCallback()\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized[\"train\"],\n",
    "    eval_dataset=tokenized[\"test\"],\n",
    "    data_collator=DataCollatorForLanguageModeling(tokenizer, mlm=False),\n",
    "    callbacks=[loss_logger, EarlyStoppingCallback(early_stopping_patience=3)]\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Extract data\n",
    "train_epochs, train_losses = zip(*loss_logger.train_logs)\n",
    "eval_epochs, eval_losses = zip(*loss_logger.eval_logs)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(train_epochs, train_losses, label=\"Training Loss\", marker='o')\n",
    "plt.plot(eval_epochs, eval_losses, label=\"Validation Loss\", marker='s')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training vs. Validation Loss\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./lora-deepseek-1.5b-adapter\\\\tokenizer_config.json',\n",
       " './lora-deepseek-1.5b-adapter\\\\special_tokens_map.json',\n",
       " './lora-deepseek-1.5b-adapter\\\\tokenizer.json')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained(\"./lora-deepseek-1.5b-adapter\")\n",
    "tokenizer.save_pretrained(\"./lora-deepseek-1.5b-adapter\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running evaluation on TEST SET only\n",
      "ðŸ” Evaluating department_management (4 questions)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "department_management:   0%|          | 0/4 [00:00<?, ?it/s]c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "department_management:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:02<00:00,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query failed: Execution failed on sql '\n",
      "SELECT t2.name\n",
      "FROM head AS t1\n",
      "JOIN management AS t2 ON t1.department_id = t2.department_id\n",
      "WHERE t1.name = \"John Doe\" WHERE t2.born_state = \"California\"': near \"WHERE\": syntax error\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "department_management: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query failed: Execution failed on sql '\n",
      "SELECT department_id,\n",
      "       name,\n",
      "       count(*)\n",
      "FROM management\n",
      "WHERE head_id NOT IN\n",
      "    (SELECT head_id\n",
      "     FROM head)\n",
      "ORDER BY 1': no such column: name\n",
      "âœ… Accuracy for department_management: 2/4 = 50.00%\n",
      "ðŸ” Evaluating farm (10 questions)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "farm:   0%|          | 0/10 [00:00<?, ?it/s]c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "farm:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:04<00:03,  1.42it/s]c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "farm:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:04<00:02,  1.69it/s]c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "farm:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [00:06<00:01,  1.46it/s]c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "farm: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:08<00:00,  1.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query failed: Execution failed on sql '\n",
      "SELECT T2.Theme\n",
      "FROM farm_competition AS T1\n",
      "JOIN farm_competition_intercept ON T1.Farm_ID = T2.Farm_ID\n",
      "JOIN farm_competition_intercept2 ON T2.Farm_ID = FARM_ID': no such table: farm_competition_intercept\n",
      "âœ… Accuracy for farm: 6/10 = 60.00%\n",
      "ðŸ” Evaluating aircraft (12 questions)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "aircraft:   0%|          | 0/12 [00:00<?, ?it/s]c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "aircraft:   8%|â–Š         | 1/12 [00:01<00:12,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query failed: Execution failed on sql '\n",
      "SELECT Airport_Name,\n",
      "       International_Passengers\n",
      "FROM airport\n",
      "WHERE INTIMAL_PASSERS > 100000': no such column: INTIMAL_PASSERS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "aircraft:  17%|â–ˆâ–‹        | 2/12 [00:03<00:17,  1.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query failed: Execution failed on sql '\n",
      "SELECT airport_name,\n",
      "       aircraft_id\n",
      "FROM airport\n",
      "JOIN airport_aircraft ON airport_aircraft.aircraft_id = airport.aircraft.aircraft_id INTERSECT\n",
      "SELECT airport_name,\n",
      "       aircraft_id\n",
      "FROM airport\n",
      "WHERE airport_aircraftID = airport_aircraft.aircraft_id': no such column: aircraft_id\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "aircraft:  25%|â–ˆâ–ˆâ–Œ       | 3/12 [00:04<00:13,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query failed: Execution failed on sql '\n",
      "SELECT T2.Aircraft\n",
      "FROM aircraft AS T1\n",
      "JOIN airport_aircraft AS T2 ON T1.Aircraft_ID = T2.Aircraft PRIMARY KEY (T2.Aircraft)': near \"PRIMARY\": syntax error\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "aircraft:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 4/12 [00:08<00:18,  2.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query failed: Execution failed on sql '\n",
      "SELECT T2.Name\n",
      "FROM aircraft AS T1\n",
      "JOIN airport_aircraft AS T2 ON T1.Aircraft_ID = T2.Aircraft_ID\n",
      "WHERE T1.Pilot_ID = '3' WHERE T2.Aircraft_ID NOT IN\n",
      "    (SELECT T3.Aircraft_ID\n",
      "     FROM match AS T4\n",
      "     JOIN aircraft AS T5\n",
      "     JOIN airport_aircraft AS T6 ON T5.Aircraft_ID = T6.Aircraft_ID\n",
      "     WHERE T5.Pilot_ID = '3')': near \"WHERE\": syntax error\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "aircraft:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 5/12 [00:09<00:13,  1.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query failed: Execution failed on sql '\n",
      "SELECT T2.Aircraft\n",
      "FROM aircraft AS T1\n",
      "JOIN airport_aircraft AS T2 ON T1.Aircraft_ID = T2.Aircraft\n",
      "WHERE T1.Aircraft = 'None'': no such column: T2.Aircraft\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "aircraft:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 6/12 [00:10<00:09,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query failed: Execution failed on sql '\n",
      "SELECT Name,\n",
      "       Age\n",
      "FROM pilot WHEREå¹´é¾„ < 30\n",
      "ORDER BY å¹´é¾„ DESC\n",
      "LIMIT 1': near \"<\": syntax error\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "aircraft:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 9/12 [00:11<00:02,  1.16it/s]c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "aircraft:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 10/12 [00:12<00:01,  1.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query failed: Execution failed on sql '\n",
      "SELECT T2.Aircraft\n",
      "FROM aircraft AS T1\n",
      "JOIN airport_aircraft AS T2 ON T1.Aircraft_ID = T2.Aircraft': no such column: T2.Aircraft\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "aircraft:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 11/12 [00:14<00:01,  1.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query failed: Execution failed on sql '\n",
      "SELECT INT(International_Passengers),\n",
      "       INT(Domestic_Passengers)\n",
      "FROM airport\n",
      "WHERE Airport_Name LIKE '%Int% \" INT(International_Passengers) , INT(Domestic_Passengers) FROM airport WHERE Airport_Name  LIKE '%Di% \"': unrecognized token: \"\"\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "aircraft: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:17<00:00,  1.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query failed: Execution failed on sql '\n",
      "SELECT airport.name,\n",
      "       aircraft.Aircraft\n",
      "FROM airport\n",
      "LEFT JOIN airport_aircraft ON airport.Aircraft_ID = airport_aircraft.Aircraft_ID\n",
      "LEFT JOIN airport_aircraft ON airport_aircraft.Aircraft_ID = airport_aircraft.Aircraft_ID INTERSECT\n",
      "SELECT w.name,\n",
      "       w.Aircraft\n",
      "FROM aircraft\n",
      "LEFT JOIN airport_aircraft ON airport_aircraft.Aircraft_ID = airport_aircraft.Aircraft_ID': no such column: w.name\n",
      "âœ… Accuracy for aircraft: 2/12 = 16.67%\n",
      "ðŸ” Evaluating architecture (5 questions)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "architecture:   0%|          | 0/5 [00:00<?, ?it/s]c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "architecture:  20%|â–ˆâ–ˆ        | 1/5 [00:00<00:02,  1.62it/s]c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "architecture:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:01<00:02,  1.32it/s]c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "architecture:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:02<00:01,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query failed: Execution failed on sql '\n",
      "SELECT DISTINCT NAMEDISTANCE\n",
      "FROM architect\n",
      "WHERE NAMEDISTANCE = \"Tompkins\" ;': no such column: NAMEDISTANCE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "architecture:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:03<00:00,  1.15it/s]c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "architecture: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:05<00:00,  1.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Accuracy for architecture: 0/5 = 0.00%\n",
      "ðŸ” Evaluating cinema (8 questions)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cinema:   0%|          | 0/8 [00:00<?, ?it/s]c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "cinema:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:03<00:06,  1.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query failed: Execution failed on sql '\n",
      "SELECT T1.title,\n",
      "       T1.title,\n",
      "       T1.title,\n",
      "       T1.title\n",
      "FROM film AS T1\n",
      "JOIN cinema AS T2 ON T1.cinema_id = T2.cinema_id\n",
      "JOIN schedule AS T3 ON T1.cinema_id = T3.cinema_id\n",
      "WHERE T3.price = 100': no such column: T1.cinema_id\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "cinema:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:04<00:02,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query failed: Execution failed on sql '\n",
      "SELECT name,\n",
      "ORDER BY openning_year\n",
      "FROM cinema': near \"ORDER\": syntax error\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "cinema:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:05<00:01,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query failed: Execution failed on sql '\n",
      "SELECT name,\n",
      "       location\n",
      "FROM cinema\n",
      "WHERE capacity MAX': near \"MAX\": syntax error\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "cinema: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:07<00:00,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query failed: Execution failed on sql '\n",
      "SELECT T2.title,\n",
      "       T2.director\n",
      "FROM schedule AS T1\n",
      "JOIN film AS T2 ON T1.film_id = T2.film_id\n",
      "WHERE T1.date = 'none'': no such column: T2.director\n",
      "âœ… Accuracy for cinema: 4/8 = 50.00%\n",
      "\n",
      "ðŸ“Š Summary of Accuracy per Dataset:\n",
      " - department_management: 2/4 = 50.00%\n",
      " - farm: 6/10 = 60.00%\n",
      " - aircraft: 2/12 = 16.67%\n",
      " - architecture: 0/5 = 0.00%\n",
      " - cinema: 4/8 = 50.00%\n",
      "\n",
      "ðŸŽ¯ Final Accuracy: 14/39 = 35.90%\n",
      "Saved bad cases to bad_cases_lora-finetuned_deepseek-1.5b_test_cases.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "data = test_data\n",
    "\n",
    "import sqlite3\n",
    "import json\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import sqlparse\n",
    "\n",
    "# Path config\n",
    "def get_db_path(db_id):\n",
    "    base_dir = Path(r\"C:\\Users\\zly20\\OneDrive - The University of Western Ontario\\1B\\CS 9860 Advanced Machine Learning\\Final Project\\CS_9860_Final_Project\\data\")\n",
    "    return str(base_dir / f\"{db_id}.sqlite\")\n",
    "\n",
    "# Run SQL and return DataFrame\n",
    "def run_query_on_db(db_path, query):\n",
    "    try:\n",
    "        with sqlite3.connect(db_path) as conn:\n",
    "            result = pd.read_sql_query(query, conn)\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        print(\"Query failed:\", e)\n",
    "        return None\n",
    "\n",
    "def results_match(df1, df2):\n",
    "    try:\n",
    "        # Lowercase column names for case-insensitive comparison\n",
    "        df1.columns = [c.lower() for c in df1.columns]\n",
    "        df2.columns = [c.lower() for c in df2.columns]\n",
    "\n",
    "        # Sort columns so order doesn't matter\n",
    "        df1 = df1[df1.columns.sort_values()]\n",
    "        df2 = df2[df2.columns.sort_values()]\n",
    "\n",
    "        # Sort rows and reset index\n",
    "        df1 = df1.sort_values(by=list(df1.columns)).reset_index(drop=True)\n",
    "        df2 = df2.sort_values(by=list(df2.columns)).reset_index(drop=True)\n",
    "\n",
    "        # Compare actual values\n",
    "        return df1.equals(df2)\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "\n",
    "# Accumulators\n",
    "correct = 0\n",
    "total = 0\n",
    "bad_cases = []\n",
    "\n",
    "# Per-dataset tracking\n",
    "correct_by_db = {}\n",
    "total_by_db = {}\n",
    "\n",
    "print(\"Running evaluation on TEST SET only\")\n",
    "\n",
    "# Loop through each database and use corresponding prompt\n",
    "for db_id, prompt_template in dbs:\n",
    "    subset = [item for item in data if item[\"db_id\"] == db_id]\n",
    "    db_path = get_db_path(db_id)\n",
    "\n",
    "    correct_local = 0\n",
    "    total_local = 0\n",
    "\n",
    "    def generate_query(question):\n",
    "        prompt = prompt_template.format(question=question)\n",
    "        inputs = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "        generated_ids = model.generate(\n",
    "            **inputs,\n",
    "            num_return_sequences=1,\n",
    "            eos_token_id=tokenizer.eos_token_id,\n",
    "            pad_token_id=tokenizer.eos_token_id,\n",
    "            max_new_tokens=168,\n",
    "            do_sample=False,\n",
    "            num_beams=1,\n",
    "        )\n",
    "        outputs = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)\n",
    "        return sqlparse.format(outputs[0].split(\"[SQL]\")[1].split(\"[/SQL]\")[0], reindent=True)\n",
    "\n",
    "    print(f\"ðŸ” Evaluating {db_id} ({len(subset)} questions)\")\n",
    "    for item in tqdm(subset, desc=f\"{db_id}\"):\n",
    "        question = item[\"question\"]\n",
    "        gold_query = item[\"query\"]\n",
    "\n",
    "        try:\n",
    "            pred_query = generate_query(question)\n",
    "\n",
    "            gold_result = run_query_on_db(db_path, gold_query)\n",
    "            pred_result = run_query_on_db(db_path, pred_query)\n",
    "\n",
    "            if gold_result is not None and pred_result is not None:\n",
    "                if gold_result.equals(pred_result):\n",
    "                    correct += 1\n",
    "                    correct_local += 1\n",
    "                else:\n",
    "                    bad_cases.append({\n",
    "                        \"db_id\": db_id,\n",
    "                        \"question\": question,\n",
    "                        \"gold_query\": gold_query,\n",
    "                        \"pred_query\": pred_query,\n",
    "                        \"error_type\": \"Mismatch\",\n",
    "                        \"gold_result\": gold_result.to_string(index=False),\n",
    "                        \"pred_result\": pred_result.to_string(index=False)\n",
    "                    })\n",
    "            else:\n",
    "                bad_cases.append({\n",
    "                    \"db_id\": db_id,\n",
    "                    \"question\": question,\n",
    "                    \"gold_query\": gold_query,\n",
    "                    \"pred_query\": pred_query,\n",
    "                    \"error_type\": \"ExecutionError\",\n",
    "                    \"gold_result\": str(gold_result),\n",
    "                    \"pred_result\": str(pred_result)\n",
    "                })\n",
    "\n",
    "            total += 1\n",
    "            total_local += 1\n",
    "\n",
    "        except Exception as e:\n",
    "            bad_cases.append({\n",
    "                \"db_id\": db_id,\n",
    "                \"question\": question,\n",
    "                \"gold_query\": gold_query,\n",
    "                \"pred_query\": \"N/A\",\n",
    "                \"error_type\": f\"Exception: {str(e)}\",\n",
    "                \"gold_result\": \"N/A\",\n",
    "                \"pred_result\": \"N/A\"\n",
    "            })\n",
    "            total += 1\n",
    "            total_local += 1\n",
    "            continue\n",
    "\n",
    "    correct_by_db[db_id] = correct_local\n",
    "    total_by_db[db_id] = total_local\n",
    "    print(f\"âœ… Accuracy for {db_id}: {correct_local}/{total_local} = {correct_local / total_local:.2%}\")\n",
    "\n",
    "output_filename = \"bad_cases_lora-finetuned_deepseek-1.5b_test_cases.json\"\n",
    "\n",
    "with open(output_filename, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump({\n",
    "        \"model_name\": \"lora-finetuned_deepseek-1.5b\",\n",
    "        \"final_accuracy\": correct / total,\n",
    "        \"per_dataset_accuracy\": {\n",
    "            db_id: correct_by_db[db_id] / total_by_db[db_id] for db_id in correct_by_db\n",
    "        },\n",
    "        \"bad_cases\": bad_cases\n",
    "    }, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(\"\\nðŸ“Š Summary of Accuracy per Dataset:\")\n",
    "for db_id in correct_by_db:\n",
    "    print(f\" - {db_id}: {correct_by_db[db_id]}/{total_by_db[db_id]} = {correct_by_db[db_id] / total_by_db[db_id]:.2%}\")\n",
    "\n",
    "print(f\"\\nðŸŽ¯ Final Accuracy: {correct}/{total} = {correct / total:.2%}\")\n",
    "print(f\"Saved bad cases to {output_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance on Entire Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\accelerate\\utils\\modeling.py:1536: UserWarning: Current model requires 256 bytes of buffer for offloaded layers, which seems does not fit any GPU's remaining memory. If you are experiencing a OOM later, please consider using offload_buffers=True.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ” Evaluating department_management (16 questions)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "department_management:   0%|          | 0/16 [00:00<?, ?it/s]c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "department_management:  12%|â–ˆâ–Ž        | 2/16 [00:01<00:07,  1.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query failed: Execution failed on sql '\n",
      "SELECT name,\n",
      "       born state,\n",
      "       age\n",
      "FROM head\n",
      "ORDER BY age': no such column: born\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "department_management:  19%|â–ˆâ–‰        | 3/16 [00:01<00:05,  2.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query failed: Execution failed on sql '\n",
      "SELECT creation,\n",
      "       name,\n",
      "       budget_in_bill\n",
      "FROM department': no such column: budget_in_bill\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "department_management:  25%|â–ˆâ–ˆâ–Œ       | 4/16 [00:02<00:06,  1.81it/s]c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "department_management:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 6/16 [00:03<00:06,  1.54it/s]c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "department_management:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 7/16 [00:03<00:05,  1.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query failed: Execution failed on sql '\n",
      "SELECT DISTINCT creation\n",
      "FROM department\n",
      "WHERE management(TEMPERARY ACTING) = 'Alabama'```': near \"ACTING\": syntax error\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "department_management:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 8/16 [00:04<00:05,  1.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query failed: Execution failed on sql '\n",
      "SELECT DISTINCT b.name\n",
      "FROM head AS b\n",
      "JOIN department AS d ON b.department_id = d.department_id\n",
      "WHERE count(d) >= 3': no such column: d\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "department_management:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 10/16 [00:06<00:04,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query failed: Execution failed on sql '\n",
      "SELECT name,\n",
      "       temporary_acting\n",
      "FROM department\n",
      "WHERE department.head_id = 3': no such column: temporary_acting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "department_management:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 11/16 [00:06<00:03,  1.58it/s]c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "department_management:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 12/16 [00:07<00:02,  1.55it/s]c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "department_management:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 13/16 [00:08<00:02,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query failed: Execution failed on sql '\n",
      "SELECT DISTINCT t1.age\n",
      "FROM head AS t1\n",
      "JOIN management AS t2 ON t1.department_ID = t2.department_ID\n",
      "WHERE t2.head_ID = 2': no such column: t1.department_ID\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "department_management:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 14/16 [00:09<00:01,  1.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query failed: Execution failed on sql '\n",
      "SELECT b.born_state\n",
      "FROM head AS b\n",
      "JOIN department AS d ON b.department_id = d.department_id\n",
      "JOIN management AS m ON d.department_id = m.department_id\n",
      "WHERE m.retailing = 2\n",
      "  AND m.working = 3\n",
      "LIMIT 10': no such column: m.retailing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "department_management:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 15/16 [00:11<00:01,  1.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query failed: Execution failed on sql '\n",
      "SELECT D.Department_ID,\n",
      "       D.Name,\n",
      "       COUNT(*)\n",
      "FROM department AS D\n",
      "JOIN head AS H ON D.Department_ID = H.head_ID\n",
      "WHERE Htemporary_acting = 'Yes'\n",
      "GROUP BY D.Department_ID\n",
      "ORDER BY COUNT(*) DESC\n",
      "LIMIT 1': no such column: Htemporary_acting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "department_management: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:11<00:00,  1.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Accuracy for department_management: 4/16 = 25.00%\n",
      "ðŸ” Evaluating farm (40 questions)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "farm:   8%|â–Š         | 3/40 [00:00<00:11,  3.33it/s]c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "farm:  12%|â–ˆâ–Ž        | 5/40 [00:01<00:12,  2.76it/s]c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "farm:  15%|â–ˆâ–Œ        | 6/40 [00:02<00:13,  2.54it/s]c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "farm:  18%|â–ˆâ–Š        | 7/40 [00:03<00:23,  1.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query failed: Execution failed on sql '\n",
      "SELECT T2.Theme\n",
      "FROM farm_competition T1\n",
      "JOIN farm_competition T2 ON T1.Farm_ID = T2.Farm_ID\n",
      "ORDER BY T1.Year ASC': no such column: T1.Farm_ID\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "farm:  20%|â–ˆâ–ˆ        | 8/40 [00:04<00:30,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query failed: Execution failed on sql '\n",
      "SELECT T2.Theme\n",
      "FROM farm_competition T1\n",
      "JOIN farm_competition T2 ON T1.Farm_ID = T2.Farm_ID\n",
      "ORDER BY T1.Year ASC': no such column: T1.Farm_ID\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "farm:  22%|â–ˆâ–ˆâ–Ž       | 9/40 [00:05<00:27,  1.13it/s]c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "farm:  25%|â–ˆâ–ˆâ–Œ       | 10/40 [00:06<00:25,  1.16it/s]c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "farm:  30%|â–ˆâ–ˆâ–ˆ       | 12/40 [00:07<00:20,  1.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query failed: Execution failed on sql '\n",
      "SELECT MAX(Cows)\n",
      "FROM farm\n",
      "WHERE Farmer_ID != NULL\n",
      "ORDER BY MAX(Cows) DESC\n",
      "LIMIT 1': no such column: Farmer_ID\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "farm:  32%|â–ˆâ–ˆâ–ˆâ–Ž      | 13/40 [00:08<00:19,  1.42it/s]c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "farm:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 19/40 [00:11<00:13,  1.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query failed: Execution failed on sql '\n",
      "SELECT T1.Year,\n",
      "       T1.Official_Name\n",
      "FROM city AS T1\n",
      "JOIN farm_competition AS T2 ON T1.City_ID = T2.Host_city_ID\n",
      "ORDER BY T1.Year ASC': no such column: T1.Year\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "farm:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 20/40 [00:12<00:14,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query failed: Execution failed on sql '\n",
      "SELECT T1.year,\n",
      "       T1official_name\n",
      "FROM city AS T1\n",
      "JOIN farm_competition AS T2 ON T1.city_ID = T2.host_city_ID\n",
      "ORDER BY T2.year DESC ```': unrecognized token: \"```\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "farm:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 21/40 [00:12<00:12,  1.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query failed: Execution failed on sql '\n",
      "SELECT Official_Name\n",
      "FROM city\n",
      "WHERE City_ID NOT EXISTS\n",
      "  SELECT City_ID\n",
      "  FROM city\n",
      "GROUP BY City_ID': near \"EXISTS\": syntax error\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "farm:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 22/40 [00:13<00:11,  1.59it/s]c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "farm:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 24/40 [00:15<00:15,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query failed: Execution failed on sql '\n",
      "SELECT T1.Status\n",
      "FROM city AS T1\n",
      "JOIN farm_competition AS T2 ON T1.City_ID = T2.Host_city_ID\n",
      "GROUP BY T1.City_ID\n",
      "ORDER BY COUNT(T2) DESC\n",
      "LIMIT 1': no such column: T2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "farm:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 25/40 [00:16<00:14,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query failed: Execution failed on sql '\n",
      "SELECT T2.Theme\n",
      "FROM city AS T1\n",
      "JOIN farm_competition AS T2 ON T1.City_ID = T2.Host_city_ID\n",
      "WHERE T1 POPULATION > 1000': near \"POPULATION\": syntax error\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "farm:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 26/40 [00:17<00:13,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query failed: Execution failed on sql '\n",
      "SELECT T2.Theme\n",
      "FROM city AS T1\n",
      "JOIN farm_competition AS T2 ON T1.City_ID = T2.Host_city_ID\n",
      "WHERE T1 POPULATION > 1000': near \"POPULATION\": syntax error\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "farm:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 27/40 [00:18<00:10,  1.26it/s]c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "farm:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 28/40 [00:18<00:08,  1.48it/s]c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "farm:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 33/40 [00:21<00:04,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query failed: Execution failed on sql '\n",
      "SELECT Official_Name\n",
      "FROM city\n",
      "WHERE NOT EXISTS\n",
      "    (SELECT Population\n",
      "     FROM competition\n",
      "     WHERE Competition_ID NOT IN\n",
      "         (SELECT Competition_ID\n",
      "          FROM competition_competition\n",
      "          WHERE State = 'None'))': no such table: competition\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "farm:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 34/40 [00:22<00:04,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query failed: Execution failed on sql '\n",
      "SELECT Official_Name\n",
      "FROM city\n",
      "WHERE NOT EXISTS\n",
      "    (SELECT DISTINCT City_ID\n",
      "     FROM farm_competition\n",
      "     WHERE Competition_ID = ?)': Incorrect number of bindings supplied. The current statement uses 1, and there are 0 supplied.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "farm:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 35/40 [00:22<00:03,  1.41it/s]c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "farm:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 36/40 [00:24<00:03,  1.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query failed: Execution failed on sql '\n",
      "SELECT T2.Status\n",
      "FROM city AS T1\n",
      "JOIN farm_competition AS T2 ON T1.City_ID = T2.Host_city_ID\n",
      "WHERE T1 POPULATION > 1500\n",
      "  AND T2.Rank = 3': near \"POPULATION\": syntax error\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "farm:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 39/40 [00:26<00:00,  1.23it/s]c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "farm: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:26<00:00,  1.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Accuracy for farm: 17/40 = 42.50%\n",
      "ðŸ” Evaluating aircraft (46 questions)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "aircraft:   4%|â–         | 2/46 [00:00<00:12,  3.39it/s]c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "aircraft:   7%|â–‹         | 3/46 [00:00<00:12,  3.52it/s]c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "aircraft:   9%|â–Š         | 4/46 [00:01<00:11,  3.56it/s]c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "aircraft:  11%|â–ˆ         | 5/46 [00:01<00:16,  2.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query failed: Execution failed on sql '\n",
      "SELECT avg(international_Passengers)\n",
      "FROM airport\n",
      "WHERE airport NOT EXISTS\n",
      "  SELECT count(*)\n",
      "  FROM airport WHERE airport NOT EXISTS': near \"EXISTS\": syntax error\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "aircraft:  13%|â–ˆâ–Ž        | 6/46 [00:03<00:37,  1.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query failed: Execution failed on sql '\n",
      "SELECT avg(international_Passengers)\n",
      "FROM airport\n",
      "WHERE airport ( intentionally returning 'I do not know' if I cannot answer the question with the available database schema 'I do not know' if I cannot answer the question with the available database schema\n",
      "SELECT avg(international_Passengers)\n",
      "FROM airport': near \"returning\": syntax error\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "aircraft:  15%|â–ˆâ–Œ        | 7/46 [00:04<00:38,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query failed: Execution failed on sql '\n",
      "SELECT count(IIF(CASE\n",
      "                     WHEN Airport_Name = 'London \"Heathrow\"' THEN 1\n",
      "                     ELSE 0\n",
      "                 END), 1, 2)\n",
      "FROM airport': wrong number of arguments to function IIF()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "aircraft:  17%|â–ˆâ–‹        | 8/46 [00:05<00:32,  1.16it/s]c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "aircraft:  20%|â–ˆâ–‰        | 9/46 [00:06<00:33,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query failed: Execution failed on sql '\n",
      "SELECT D.Domestic_Passengers\n",
      "FROM airport\n",
      "WHERE Airport_Name LIKE '%London%'\n",
      "ORDER BY D.Domestic_Passengers ASC\n",
      "LIMIT 1': no such column: D.Domestic_Passengers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "aircraft:  22%|â–ˆâ–ˆâ–       | 10/46 [00:07<00:30,  1.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query failed: Execution failed on sql '\n",
      "SELECT DISTINCT DDomestic_Passengers\n",
      "FROM airport\n",
      "WHERE Airport_Name LIKE '%London%'': no such column: DDomestic_Passengers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "aircraft:  24%|â–ˆâ–ˆâ–       | 11/46 [00:08<00:32,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query failed: Execution failed on sql '\n",
      "SELECT MIN(Transit_Passengers) AS MINTransitPassengers,\n",
      "       MAX(Transit_Passengers) AS MAXTransitPassengers\n",
      "FROM airport\n",
      "WHERE Airport_Name LIKE '%_2007%\";': unrecognized token: \"'%_2007%\";\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "aircraft:  26%|â–ˆâ–ˆâ–Œ       | 12/46 [00:09<00:32,  1.04it/s]c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "aircraft:  28%|â–ˆâ–ˆâ–Š       | 13/46 [00:10<00:32,  1.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query failed: Execution failed on sql '\n",
      "SELECT DISTINCT T1.Name\n",
      "FROM aircraft AS T1\n",
      "JOIN pilot AS T2 ON T1.Aircraft_ID = T2.Pilot_Id\n",
      "WHERE T2.Age >= 25': no such column: T1.Name\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "aircraft:  30%|â–ˆâ–ˆâ–ˆ       | 14/46 [00:11<00:34,  1.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query failed: Execution failed on sql '\n",
      "SELECT DISTINCT T1.Name\n",
      "FROM pilot AS T1\n",
      "JOIN aircraft AS T2 ON T1.Aircraft_ID = T2.Aircraft_ID\n",
      "WHERE T2.Aircraft_ID = NULL WHERE T1.Age >= 25': near \"WHERE\": syntax error\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "aircraft:  35%|â–ˆâ–ˆâ–ˆâ–      | 16/46 [00:12<00:22,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query failed: Execution failed on sql '\n",
      "SELECT names\n",
      "FROM pilot\n",
      "ORDER BY name ASC': no such column: names\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "aircraft:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 17/46 [00:13<00:21,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query failed: Execution failed on sql '\n",
      "SELECT L.Name\n",
      "FROM pilot AS T\n",
      "WHERE T.Aged <= 30\n",
      "ORDER BY L.Name DESC': no such column: L.Name\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "aircraft:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 18/46 [00:15<00:30,  1.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query failed: Execution failed on sql '\n",
      "SELECT DISTINCT T1.Name\n",
      "FROM pilot AS T1\n",
      "JOIN aircraft AS T2 ON T1.Aircraft_ID = T2.Aircraft_ID\n",
      "WHERE T2.Aircraft_ID = 200 IN\n",
      "    (SELECT MAX(Aircraft.Max_Gross_Weight)\n",
      "     FROM aircraft)\n",
      "LIMIT 500': no such column: T1.Aircraft_ID\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "aircraft:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 19/46 [00:15<00:26,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query failed: Execution failed on sql '\n",
      "SELECT Aircraft\n",
      "FROM aircraft\n",
      "WHERE Pilot_ID = 11\n",
      "  AND Aircraft_ID\n",
      "  FROM airport WHERE Airport_Name = 'London Gatwick'': near \"FROM\": syntax error\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "aircraft:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20/46 [00:16<00:21,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query failed: Execution failed on sql '\n",
      "SELECT Aircraft\n",
      "FROM aircraft\n",
      "WHERE Pilot_ID = '2000'': no such column: Pilot_ID\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "aircraft:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21/46 [00:17<00:20,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query failed: Execution failed on sql '\n",
      "SELECT A.Aircraft\n",
      "FROM aircraft AS A\n",
      "WHERE A.Total_Passengers > 10000000': no such column: A.Total_Passengers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "aircraft:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 22/46 [00:17<00:18,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query failed: Execution failed on sql '\n",
      "SELECT A.Aircraft\n",
      "FROM aircraft AS A\n",
      "WHERE A.Total_Passengers > 10000000': no such column: A.Total_Passengers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "aircraft:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 23/46 [00:18<00:17,  1.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query failed: Execution failed on sql '\n",
      "SELECT avg(Total_Passengers)\n",
      "FROM airport\n",
      "WHERE airportå…³è” pilot WHERE pilot.Aircraft_ID = 22': near \"pilot\": syntax error\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "aircraft:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24/46 [00:19<00:16,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query failed: Execution failed on sql '\n",
      "SELECT avg(Total_Passengers)\n",
      "FROM airport\n",
      "WHERE airport_winning_pilot = 'Robinson R-22'': no such column: airport_winning_pilot\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "aircraft:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/46 [00:19<00:13,  1.61it/s]c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "aircraft:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 26/46 [00:19<00:11,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query failed: Execution failed on sql '\n",
      "SELECT *Aircraft\n",
      "FROM match\n",
      "WHERE Winning_Pilot = ?': near \"Aircraft\": syntax error\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "aircraft:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27/46 [00:20<00:13,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query failed: Execution failed on sql '\n",
      "SELECT A.WINNING_Aircraft\n",
      "FROM aircraft AS W\n",
      "WHERE W.Winning_Pilot = 'Winning Aircraft'\n",
      "GROUP BY A.WINNING_Aircraft\n",
      "ORDER BY COUNT(*) ASC\n",
      "LIMIT 1': no such column: A.WINNING_Aircraft\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "aircraft:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 28/46 [00:21<00:14,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query failed: Execution failed on sql '\n",
      "SELECT T2.Aircraft\n",
      "FROM aircraft AS T1\n",
      "JOIN aircraft_aircraft AS T2 ON T1.Aircraft_ID = T2.Aircraft PRIMARY KEY (T2.Aircraft)': near \"PRIMARY\": syntax error\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "aircraft:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 29/46 [00:22<00:14,  1.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query failed: Execution failed on sql '\n",
      "SELECT Aircraft\n",
      "FROM aircraft\n",
      "JOIN WINNING_Aircraft\n",
      "FROM match\n",
      "WHERE Winning_Pilot = 'Kirk'\n",
      "ORDER BY Aircraft ASC': near \"FROM\": syntax error\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "aircraft:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 30/46 [00:23<00:12,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query failed: Execution failed on sql '\n",
      "SELECT Aircraft\n",
      "FROM aircraft\n",
      "WHERE winning_airsport IS NOT NULL': no such column: winning_airsport\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "aircraft:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 33/46 [00:25<00:07,  1.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query failed: Execution failed on sql '\n",
      "SELECT Aircraft\n",
      "FROM aircraft\n",
      "WHERE EXISTS\n",
      "  SELECT name\n",
      "  FROM pilot WHERE EXISTS': near \"SELECT\": syntax error\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "aircraft:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34/46 [00:27<00:12,  1.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query failed: Execution failed on sql '\n",
      "SELECT A.WINNING_Aircraft\n",
      "FROM aircraft\n",
      "WHERE EXISTS\n",
      "  SELECT A1.WINNING_Aircraft\n",
      "  FROM aircraft AS A\n",
      "  FROM aircraft AS A2\n",
      "  JOIN MATCH ON A.Aircraft_ID 2 WHERE EXISTS\n",
      "  SELECT DISTINCT R.Winning_Aircraft\n",
      "  FROM match AS T\n",
      "  JOIN aircraft AS A\n",
      "  FROM airport_aircraft AS RA ON R.AIRPORT_ID 1 WHERE EXISTS': near \"SELECT\": syntax error\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "aircraft:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 35/46 [00:27<00:09,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query failed: Execution failed on sql '\n",
      "SELECT DISTINCT A.Aircraft\n",
      "FROM aircraft\n",
      "WHERE NOT EXISTS\n",
      "  SELECT P.Winning_Pilot\n",
      "  FROM match WHERE Winning_Pilot NOT NULL': near \"SELECT\": syntax error\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "aircraft:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 36/46 [00:28<00:10,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query failed: Execution failed on sql '\n",
      "SELECT T2.Aircraft\n",
      "FROM aircraft AS T1\n",
      "JOIN aircraft_twinning_wins ON T1.Aircraft_ID = T2.Aircraft\n",
      "WHERE T1.Aircraft_ID NOT IN\n",
      "    (SELECT T1.Aircraft_ID\n",
      "     FROM aircraft_twinning_wins\n",
      "     WHERE Winning_Pilot NOT NULL)': no such table: aircraft_twinning_wins\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "aircraft:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 37/46 [00:30<00:11,  1.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query failed: Execution failed on sql '\n",
      "SELECT Aircraft\n",
      "FROM aircraft\n",
      "WHERE pilot_id IN\n",
      "    (SELECT *\n",
      "     FROM pilot\n",
      "     WHERE pilot_id = '3')\n",
      "  AND aircraft_id IN\n",
      "    (SELECT *\n",
      "     FROM aircraft\n",
      "     WHERE airport_id IN\n",
      "         (SELECT airportID\n",
      "          FROM airport\n",
      "          WHERE airport_name = 'London Heathrow')\n",
      "       AND airport_id IN\n",
      "         (SELECT airportID\n",
      "          FROM airport\n",
      "          WHERE airport_name = 'London Gatwick'))': no such column: pilot_id\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "aircraft:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 38/46 [00:32<00:12,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query failed: Execution failed on sql '\n",
      "SELECT A.Aircraft\n",
      "FROM aircraft AS A\n",
      "WHERE A.Aircraft_ID IN\n",
      "    (SELECT Aircraft.Aircraft\n",
      "     FROM aircraft AS B\n",
      "     WHERE B.Aircraft_ID IN\n",
      "         (SELECT id\n",
      "          FROM pilot AS C\n",
      "          WHERE C.Pilot_Id = '1000000000000000000')\n",
      "       AND A.Aircraft_ID = B.Aircraft_ID)\n",
      "GROUP BY A.Aircraft\n",
      "ORDER BY A.Aircraft ASC': no such column: Aircraft.Aircraft\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "aircraft:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/46 [00:33<00:08,  1.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query failed: Execution failed on sql '\n",
      "SELECT *\n",
      "FROM airport\n",
      "WHERE airportInternational_Passengers MAX': near \"MAX\": syntax error\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "aircraft:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 40/46 [00:33<00:05,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query failed: Execution failed on sql '\n",
      "SELECT *\n",
      "FROM airport\n",
      "WHERE airportInternational_Passengers MAX': near \"MAX\": syntax error\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "aircraft:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 41/46 [00:34<00:05,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query failed: Execution failed on sql '\n",
      "SELECT T2.Name,\n",
      "       T2.Age\n",
      "FROM aircraft AS T1\n",
      "JOIN match AS T2 ON T1.Aircraft_ID = T2.Winning_Pilot\n",
      "GROUP BY T1.Aircraft_ID\n",
      "ORDER BY COUNT(*) DESC\n",
      "LIMIT 1': no such column: T2.Name\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "aircraft:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 42/46 [00:36<00:04,  1.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query failed: Execution failed on sql '\n",
      "SELECT T1.Name,\n",
      "       T1.Age\n",
      "FROM pilot AS T1\n",
      "JOIN MATCH AS T2 ON T1.Aircraft_ID = T2.Winning_Pilot\n",
      "GROUP BY T1.Aircraft_ID\n",
      "ORDER BY COUNT(*) DESC\n",
      "LIMIT 1': no such column: T1.Aircraft_ID\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "aircraft:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 43/46 [00:37<00:03,  1.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query failed: Execution failed on sql '\n",
      "SELECT T1.Name,\n",
      "       T1.Age\n",
      "FROM pilot AS T1\n",
      "JOIN aircraft AS T2 ON T1.Aircraft_ID = T2.Aircraft_ID\n",
      "WHERE T2.Winning_Pilot = 'Jack nominated'\n",
      "ORDER BY T1.Age ASC\n",
      "LIMIT 1': no such column: T2.Winning_Pilot\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "aircraft:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 44/46 [00:38<00:02,  1.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query failed: Execution failed on sql '\n",
      "SELECT T1.Age, (* name of the pilot)*\n",
      "FROM pilot AS T1\n",
      "JOIN winning_pilot AS T2 ON T1.Aircraft_ID = T2.Winning_Pilot\n",
      "ORDER BY T1.Aircraft_ID ASC\n",
      "LIMIT 1': near \"*\": syntax error\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "aircraft:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 45/46 [00:39<00:01,  1.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query failed: Execution failed on sql '\n",
      "SELECT DISTINCT Name\n",
      "FROM pilot\n",
      "WHERE Winning_Pilot NOT IN\n",
      "    (SELECT Winning_Pilot\n",
      "     FROM match\n",
      "     WHERE Country = 'Australia')': no such column: Winning_Pilot\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "aircraft: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 46/46 [00:40<00:00,  1.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query failed: Execution failed on sql '\n",
      "SELECT DISTINCT Name\n",
      "FROM pilot\n",
      "WHERE Winning_Pilot NOT IN\n",
      "    (SELECT Winning_Pilot\n",
      "     FROM match\n",
      "     WHERE Country = 'Australia')': no such column: Winning_Pilot\n",
      "âœ… Accuracy for aircraft: 4/46 = 8.70%\n",
      "ðŸ” Evaluating architecture (17 questions)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "architecture:   0%|          | 0/17 [00:00<?, ?it/s]c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "architecture:  18%|â–ˆâ–Š        | 3/17 [00:02<00:10,  1.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query failed: Execution failed on sql '\n",
      "SELECT MAX(length_meters)\n",
      "FROM bridge\n",
      "WHERE type = 'public'\n",
      "  SELECT name\n",
      "  FROM archict WHERE id = MAX(length_meters)': near \"SELECT\": syntax error\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "architecture:  29%|â–ˆâ–ˆâ–‰       | 5/17 [00:04<00:11,  1.05it/s]c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "architecture:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 6/17 [00:04<00:10,  1.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query failed: Execution failed on sql '\n",
      "SELECT DISTINCT DISTINCT name,\n",
      "                         nationality\n",
      "FROM architect\n",
      "JOIN mill ON architect.id = mill.architect_id\n",
      "JOIN architect ON architect.id = a.id': near \"DISTINCT\": syntax error\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "architecture:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 8/17 [00:06<00:07,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query failed: Execution failed on sql '\n",
      "SELECT DISTINCT T1.name\n",
      "FROM mill AS T2\n",
      "JOIN architect AS T1 ON T2.architect_id = T1.id\n",
      "WHERE T1 nationality = 'American'\n",
      "  OR T1 nationality = 'Canadian'': near \"nationality\": syntax error\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "architecture:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 11/17 [00:10<00:07,  1.19s/it]c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "architecture:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 12/17 [00:10<00:05,  1.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query failed: Execution failed on sql '\n",
      "SELECT L localization\n",
      "FROM bridge\n",
      "WHERE name LIKE '%Kolob Arch%\n",
      "  OR %Rainbow Arch%': unrecognized token: \"'%Kolob Arch%\n",
      "  OR %Rainbow Arch%\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "architecture:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 13/17 [00:11<00:03,  1.17it/s]c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "architecture:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 14/17 [00:12<00:02,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query failed: Execution failed on sql '\n",
      "SELECT DISTINCT T1.name\n",
      "FROM mill AS T1\n",
      "JOIN architect AS T2 ON T1.architect_id = T2.id\n",
      "WHERE T2.architect_id IN (4,\n",
      "                          7)': no such column: T2.architect_id\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "architecture:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 15/17 [00:12<00:01,  1.24it/s]c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "architecture:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 16/17 [00:13<00:00,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query failed: Execution failed on sql '\n",
      "SELECT count(*)\n",
      "FROM architect\n",
      "WHERE nationality = 'US'\n",
      "  AND built_year < 1850': no such column: built_year\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "architecture: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:14<00:00,  1.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query failed: Execution failed on sql 'YourSQL\n",
      "SELECT t1.name\n",
      "FROM bridge AS t1\n",
      "JOIN architect AS t2 ON t1.architect_id = t2.id\n",
      "WHERE t2.nationality = 'American'\n",
      "ORDER BY t1.length_feet': near \"YourSQL\": syntax error\n",
      "âœ… Accuracy for architecture: 6/17 = 35.29%\n",
      "ðŸ” Evaluating cinema (30 questions)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cinema:   0%|          | 0/30 [00:00<?, ?it/s]c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "cinema:   3%|â–Ž         | 1/30 [00:00<00:11,  2.46it/s]c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "cinema:   7%|â–‹         | 2/30 [00:01<00:15,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query failed: Execution failed on sql '\n",
      "SELECT DISTINCTLocation\n",
      "FROM cinema\n",
      "WHERE cinema.Name LIKE '%2010%'\n",
      "  AND cinema.Name LIKE '%2011%'': no such column: DISTINCTLocation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "cinema:  13%|â–ˆâ–Ž        | 4/30 [00:01<00:09,  2.71it/s]c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "cinema:  20%|â–ˆâ–ˆ        | 6/30 [00:02<00:09,  2.44it/s]c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "cinema:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 10/30 [00:04<00:09,  2.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query failed: Execution failed on sql '\n",
      "SELECT Name,\n",
      "       Location\n",
      "FROM cinema\n",
      "WHERE capacity MAX': near \"MAX\": syntax error\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "cinema:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 11/30 [00:05<00:13,  1.46it/s]c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "cinema:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 12/30 [00:05<00:12,  1.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query failed: Execution failed on sql '\n",
      "SELECT DISTINCTLocation,\n",
      "       COUNT(*)\n",
      "FROM cinema\n",
      "ORDER BY COUNT(*) ASC': no such column: DISTINCTLocation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "cinema:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 13/30 [00:06<00:12,  1.34it/s]c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "cinema:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 14/30 [00:08<00:15,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query failed: Execution failed on sql '\n",
      "SELECT LOCATION\n",
      "FROM cinema\n",
      "WHERE cinema ID NOT IN\n",
      "    (SELECT Cinema_ID\n",
      "     FROM schedule\n",
      "     WHERE film ID IN (SELECTFilm_ID\n",
      "                       FROM film\n",
      "                       WHERE Title = 'THE EXTRALIKES'))\n",
      "  AND capacity > 300': near \"ID\": syntax error\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "cinema:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 15/30 [00:09<00:16,  1.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query failed: Execution failed on sql '\n",
      "SELECT LOCATION\n",
      "FROM cinema\n",
      "WHERE cinema_ID IN (SELECTFilm_ID\n",
      "                    FROM film\n",
      "                    WHERE Title IN\n",
      "                        (SELECT Title\n",
      "                         FROM schedule\n",
      "                         WHERE schedule[3] = 'Cinema'\n",
      "                           AND capacity > 300)) ) WITH COUNT(*) AS m\n",
      "  FROM cinema\n",
      "GROUP BY LOCATION\n",
      "HAVING m = 2': near \"FROM\": syntax error\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "cinema:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 16/30 [00:10<00:13,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query failed: Execution failed on sql '\n",
      "SELECT T2.title,\n",
      "       T2.director\n",
      "FROM film AS T1\n",
      "JOIN cinema AS T2 ON T1.Film_ID = T2.Cinema_ID': no such column: T2.title\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "cinema:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 17/30 [00:11<00:11,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query failed: Execution failed on sql '\n",
      "SELECT T2.title,\n",
      "       T2.director\n",
      "FROM film AS T1\n",
      "JOIN cinema AS T2 ON T1film_id = T2.cinema_id': no such column: T2.title\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "cinema:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 18/30 [00:11<00:09,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query failed: Execution failed on sql '\n",
      "SELECT DISTINCT D.title\n",
      "FROM film\n",
      "WHERE film.directed_by = D.directING\n",
      "  FROM cinema': near \"FROM\": syntax error\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "cinema:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 20/30 [00:12<00:05,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query failed: Execution failed on sql '\n",
      "SELECT Dir_name\n",
      "FROM film\n",
      "GROUP BY Dir_name\n",
      "ORDER BY COUNT(*) DESC\n",
      "LIMIT 3': no such column: Dir_name\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "cinema:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 21/30 [00:12<00:04,  1.85it/s]c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "cinema:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 22/30 [00:14<00:06,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query failed: Execution failed on sql '\n",
      "SELECT T2.title,\n",
      "       MAX(T1.price)\n",
      "FROM schedule AS T1\n",
      "JOIN film AS T2 ON T1.film_id = T2.film_id PRIMARY KEY (T1.film_id)': near \"PRIMARY\": syntax error\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "cinema:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 24/30 [00:15<00:04,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query failed: Execution failed on sql '\n",
      "SELECT name,\n",
      "       title, date, price\n",
      "FROM cinema\n",
      "JOIN schedule ON cinema ID\n",
      "JOIN film ON film ID': near \"ID\": syntax error\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "cinema:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 25/30 [00:16<00:04,  1.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query failed: Execution failed on sql '\n",
      "SELECT T2.title,\n",
      "       T2.director\n",
      "FROM schedule AS T1\n",
      "JOIN film AS T2 ON T1.film_id = T2.film_id\n",
      "WHERE T1.schedule_times_per_day = 0': no such column: T2.director\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "cinema:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 26/30 [00:17<00:03,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query failed: Execution failed on sql '\n",
      "SELECT T2.directed_by\n",
      "FROM schedule AS T1\n",
      "JOIN film AS T2 ON T1.film_id = T2.film_id\n",
      "GROUP BY T1.directed_by\n",
      "ORDER BY COUNT(T2) DESC\n",
      "LIMIT 1': no such column: T2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "cinema:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 27/30 [00:18<00:02,  1.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query failed: Execution failed on sql '\n",
      "SELECT DISTINCT LOCATION\n",
      "FROM cinema\n",
      "WHERE OPENING_YEAR = '2009'\n",
      "  AND capacity > 300': no such column: OPENING_YEAR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "cinema:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 28/30 [00:18<00:01,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query failed: Execution failed on sql '\n",
      "SELECT DISTINCT LOCATION\n",
      "FROM cinema\n",
      "WHERE cinema_name ?': near \"?\": syntax error\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "cinema: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:19<00:00,  1.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Accuracy for cinema: 9/30 = 30.00%\n",
      "\n",
      "ðŸ“Š Summary of Accuracy per Dataset:\n",
      " - department_management: 4/16 = 25.00%\n",
      " - farm: 17/40 = 42.50%\n",
      " - aircraft: 4/46 = 8.70%\n",
      " - architecture: 6/17 = 35.29%\n",
      " - cinema: 9/30 = 30.00%\n",
      "\n",
      "ðŸŽ¯ Final Accuracy: 40/149 = 26.85%\n",
      "Saved bad cases to bad_cases_lora-finetuned_deepseek-1.5b.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from peft import PeftModel\n",
    "from transformers import AutoModelForCausalLM\n",
    "\n",
    "base_model = AutoModelForCausalLM.from_pretrained(model_name, cache_dir=cache_dir, device_map=\"auto\", trust_remote_code=True)\n",
    "model = PeftModel.from_pretrained(base_model, \"./lora-deepseek-1.5b-adapter\")\n",
    "model = model.to(\"cuda\")\n",
    "\n",
    "# Load Spider dataset\n",
    "ds = load_dataset(\"spider\")\n",
    "db_ids = [\"department_management\", \"farm\", \"aircraft\", \"architecture\", \"cinema\"]\n",
    "\n",
    "data = []\n",
    "\n",
    "for db_id in db_ids:\n",
    "    subset = ds[\"train\"].filter(lambda x: x[\"db_id\"] == db_id)\n",
    "    questions = [entry[\"question\"] for entry in subset]\n",
    "    queries = [entry[\"query\"] for entry in subset]\n",
    "\n",
    "    # Combine into (db_id, question, query) triplets\n",
    "    entries = [{\"db_id\": db_id, \"question\": q, \"query\": sql} for q, sql in zip(questions, queries)]\n",
    "\n",
    "    # Add to overall list\n",
    "    data.extend(entries)\n",
    "\n",
    "import sqlite3\n",
    "import json\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import sqlparse\n",
    "\n",
    "# Path config\n",
    "def get_db_path(db_id):\n",
    "    base_dir = Path(r\"C:\\Users\\zly20\\OneDrive - The University of Western Ontario\\1B\\CS 9860 Advanced Machine Learning\\Final Project\\CS_9860_Final_Project\\data\")\n",
    "    return str(base_dir / f\"{db_id}.sqlite\")\n",
    "\n",
    "# Run SQL and return DataFrame\n",
    "def run_query_on_db(db_path, query):\n",
    "    try:\n",
    "        with sqlite3.connect(db_path) as conn:\n",
    "            result = pd.read_sql_query(query, conn)\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        print(\"Query failed:\", e)\n",
    "        return None\n",
    "\n",
    "# Accumulators\n",
    "correct = 0\n",
    "total = 0\n",
    "bad_cases = []\n",
    "\n",
    "# Per-dataset tracking\n",
    "correct_by_db = {}\n",
    "total_by_db = {}\n",
    "\n",
    "# Loop through each database and use corresponding prompt\n",
    "for db_id, prompt_template in dbs:\n",
    "    subset = [item for item in data if item[\"db_id\"] == db_id]\n",
    "    db_path = get_db_path(db_id)\n",
    "\n",
    "    correct_local = 0\n",
    "    total_local = 0\n",
    "\n",
    "    def generate_query(question):\n",
    "        prompt = prompt_template.format(question=question)\n",
    "        inputs = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "        generated_ids = model.generate(\n",
    "            **inputs,\n",
    "            num_return_sequences=1,\n",
    "            eos_token_id=tokenizer.eos_token_id,\n",
    "            pad_token_id=tokenizer.eos_token_id,\n",
    "            max_new_tokens=168,\n",
    "            do_sample=False,\n",
    "            num_beams=1,\n",
    "        )\n",
    "        outputs = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)\n",
    "        return sqlparse.format(outputs[0].split(\"[SQL]\")[1].split(\"[/SQL]\")[0], reindent=True)\n",
    "\n",
    "    print(f\"ðŸ” Evaluating {db_id} ({len(subset)} questions)\")\n",
    "    for item in tqdm(subset, desc=f\"{db_id}\"):\n",
    "        question = item[\"question\"]\n",
    "        gold_query = item[\"query\"]\n",
    "\n",
    "        try:\n",
    "            pred_query = generate_query(question)\n",
    "\n",
    "            gold_result = run_query_on_db(db_path, gold_query)\n",
    "            pred_result = run_query_on_db(db_path, pred_query)\n",
    "\n",
    "            if gold_result is not None and pred_result is not None:\n",
    "                if gold_result.equals(pred_result):\n",
    "                    correct += 1\n",
    "                    correct_local += 1\n",
    "                else:\n",
    "                    bad_cases.append({\n",
    "                        \"db_id\": db_id,\n",
    "                        \"question\": question,\n",
    "                        \"gold_query\": gold_query,\n",
    "                        \"pred_query\": pred_query,\n",
    "                        \"error_type\": \"Mismatch\",\n",
    "                        \"gold_result\": gold_result.to_string(index=False),\n",
    "                        \"pred_result\": pred_result.to_string(index=False)\n",
    "                    })\n",
    "            else:\n",
    "                bad_cases.append({\n",
    "                    \"db_id\": db_id,\n",
    "                    \"question\": question,\n",
    "                    \"gold_query\": gold_query,\n",
    "                    \"pred_query\": pred_query,\n",
    "                    \"error_type\": \"ExecutionError\",\n",
    "                    \"gold_result\": str(gold_result),\n",
    "                    \"pred_result\": str(pred_result)\n",
    "                })\n",
    "\n",
    "            total += 1\n",
    "            total_local += 1\n",
    "\n",
    "        except Exception as e:\n",
    "            bad_cases.append({\n",
    "                \"db_id\": db_id,\n",
    "                \"question\": question,\n",
    "                \"gold_query\": gold_query,\n",
    "                \"pred_query\": \"N/A\",\n",
    "                \"error_type\": f\"Exception: {str(e)}\",\n",
    "                \"gold_result\": \"N/A\",\n",
    "                \"pred_result\": \"N/A\"\n",
    "            })\n",
    "            total += 1\n",
    "            total_local += 1\n",
    "            continue\n",
    "\n",
    "    correct_by_db[db_id] = correct_local\n",
    "    total_by_db[db_id] = total_local\n",
    "    print(f\"âœ… Accuracy for {db_id}: {correct_local}/{total_local} = {correct_local / total_local:.2%}\")\n",
    "\n",
    "output_filename = \"bad_cases_lora-finetuned_deepseek-1.5b.json\"\n",
    "\n",
    "with open(output_filename, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump({\n",
    "        \"model_name\": \"lora-finetuned_deepseek-1.5b\",\n",
    "        \"final_accuracy\": correct / total,\n",
    "        \"per_dataset_accuracy\": {\n",
    "            db_id: correct_by_db[db_id] / total_by_db[db_id] for db_id in correct_by_db\n",
    "        },\n",
    "        \"bad_cases\": bad_cases\n",
    "    }, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(\"\\nðŸ“Š Summary of Accuracy per Dataset:\")\n",
    "for db_id in correct_by_db:\n",
    "    print(f\" - {db_id}: {correct_by_db[db_id]}/{total_by_db[db_id]} = {correct_by_db[db_id] / total_by_db[db_id]:.2%}\")\n",
    "\n",
    "print(f\"\\nðŸŽ¯ Final Accuracy: {correct}/{total} = {correct / total:.2%}\")\n",
    "print(f\"Saved bad cases to {output_filename}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
