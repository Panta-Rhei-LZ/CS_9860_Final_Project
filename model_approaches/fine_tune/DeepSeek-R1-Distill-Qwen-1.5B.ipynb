{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "department_prompt = \"\"\"\n",
    "### Task\n",
    "Generate a SQLite query to answer [QUESTION]{question}[/QUESTION]\n",
    "\n",
    "### Instructions\n",
    "- If you cannot answer the question with the available database schema, return 'I do not know'\n",
    "- Pay close attention to the given database schema, note on how they can join together\n",
    "- You do not need to generate your thought process but just the answer\n",
    "- Your answer should end with '[/SQL]'\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS \"department\" (\n",
    "\"Department_ID\" int,\n",
    "\"Name\" text,\n",
    "\"Creation\" text,\n",
    "\"Ranking\" int,\n",
    "\"Budget_in_Billions\" real,\n",
    "\"Num_Employees\" real,\n",
    "PRIMARY KEY (\"Department_ID\")\n",
    ");\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS \"head\" (\n",
    "\"head_ID\" int,\n",
    "\"name\" text,\n",
    "\"born_state\" text,\n",
    "\"age\" real,\n",
    "PRIMARY KEY (\"head_ID\")\n",
    ");\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS \"management\" (\n",
    "\"department_ID\" int,\n",
    "\"head_ID\" int,\n",
    "\"temporary_acting\" text,\n",
    "PRIMARY KEY (\"Department_ID\",\"head_ID\"),\n",
    "FOREIGN KEY (\"Department_ID\") REFERENCES `department`(\"Department_ID\"),\n",
    "FOREIGN KEY (\"head_ID\") REFERENCES `head`(\"head_ID\")\n",
    ");\n",
    "\n",
    "### Answer\n",
    "Given the database schema, here is the SQLite query that answers [QUESTION]{question}[/QUESTION]\n",
    "[SQL]\n",
    "\"\"\" \n",
    "\n",
    "\n",
    "farm_prompt = \"\"\"\n",
    "### Task\n",
    "Generate a SQLite query to answer [QUESTION]{question}[/QUESTION]\n",
    "\n",
    "### Instructions\n",
    "- If you cannot answer the question with the available database schema, return 'I do not know'\n",
    "- Pay close attention to the given database schema, note on how they can join together\n",
    "- You do not need to generate your thought process but just the answer\n",
    "- Your answer should end with '[/SQL]'\n",
    "\n",
    "CREATE TABLE \"city\" (\n",
    "\"City_ID\" int,\n",
    "\"Official_Name\" text,\n",
    "\"Status\" text,\n",
    "\"Area_km_2\" real,\n",
    "\"Population\" real,\n",
    "\"Census_Ranking\" text,\n",
    "PRIMARY KEY (\"City_ID\")\n",
    ");\n",
    "\n",
    "CREATE TABLE \"farm\" (\n",
    "\"Farm_ID\" int,\n",
    "\"Year\" int,\n",
    "\"Total_Horses\" real,\n",
    "\"Working_Horses\" real,\n",
    "\"Total_Cattle\" real,\n",
    "\"Oxen\" real,\n",
    "\"Bulls\" real,\n",
    "\"Cows\" real,\n",
    "\"Pigs\" real,\n",
    "\"Sheep_and_Goats\" real,\n",
    "PRIMARY KEY (\"Farm_ID\")\n",
    ");\n",
    "\n",
    "CREATE TABLE \"farm_competition\" (\n",
    "\"Competition_ID\" int,\n",
    "\"Year\" int,\n",
    "\"Theme\" text,\n",
    "\"Host_city_ID\" int,\n",
    "\"Hosts\" text,\n",
    "PRIMARY KEY (\"Competition_ID\"),\n",
    "FOREIGN KEY (`Host_city_ID`) REFERENCES `city`(`City_ID`)\n",
    ");\n",
    "\n",
    "\n",
    "CREATE TABLE \"competition_record\" (\n",
    "\"Competition_ID\" int,\n",
    "\"Farm_ID\" int,\n",
    "\"Rank\" int,\n",
    "PRIMARY KEY (\"Competition_ID\",\"Farm_ID\"),\n",
    "FOREIGN KEY (`Competition_ID`) REFERENCES `farm_competition`(`Competition_ID`),\n",
    "FOREIGN KEY (`Farm_ID`) REFERENCES `farm`(`Farm_ID`)\n",
    ");\n",
    "\n",
    "### Answer\n",
    "Given the database schema, here is the SQLite query that answers [QUESTION]{question}[/QUESTION]\n",
    "[SQL]\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "aircraft_prompt = \"\"\"\n",
    "### Task\n",
    "Generate a SQLite query to answer [QUESTION]{question}[/QUESTION]\n",
    "\n",
    "### Instructions\n",
    "- If you cannot answer the question with the available database schema, return 'I do not know'\n",
    "- Pay close attention to the given database schema, note on how they can join together\n",
    "- You do not need to generate your thought process but just the answer\n",
    "- Your answer should end with '[/SQL]'\n",
    "\n",
    "CREATE TABLE `pilot` (\n",
    "  `Pilot_Id` int(11) NOT NULL,\n",
    "  `Name` varchar(50) NOT NULL,\n",
    "  `Age` int(11) NOT NULL,\n",
    "  PRIMARY KEY (`Pilot_Id`)\n",
    ");\n",
    "\n",
    "CREATE TABLE `aircraft` (\n",
    "  \"Aircraft_ID\" int(11) NOT NULL,\n",
    "  \"Aircraft\" varchar(50) NOT NULL,\n",
    "  \"Description\" varchar(50) NOT NULL,\n",
    "  \"Max_Gross_Weight\" varchar(50) NOT NULL,\n",
    "  \"Total_disk_area\" varchar(50) NOT NULL,\n",
    "  \"Max_disk_Loading\" varchar(50) NOT NULL,\n",
    "  PRIMARY KEY (`Aircraft_ID`)\n",
    ");\n",
    "\n",
    "CREATE TABLE `match` (\n",
    "\"Round\" real,\n",
    "\"Location\" text,\n",
    "\"Country\" text,\n",
    "\"Date\" text,\n",
    "\"Fastest_Qualifying\" text,\n",
    "\"Winning_Pilot\" text,\n",
    "\"Winning_Aircraft\" text,\n",
    "PRIMARY KEY (\"Round\"),\n",
    "FOREIGN KEY (`Winning_Aircraft`) REFERENCES `aircraft`(`Aircraft_ID`),\n",
    "FOREIGN KEY (`Winning_Pilot`) REFERENCES `pilot`(`Pilot_Id`)\n",
    ");\n",
    "\n",
    "CREATE TABLE `airport` (\n",
    "\"Airport_ID\" int,\n",
    "\"Airport_Name\" text,\n",
    "\"Total_Passengers\" real,\n",
    "\"%_Change_2007\" text,\n",
    "\"International_Passengers\" real,\n",
    "\"Domestic_Passengers\" real,\n",
    "\"Transit_Passengers\" real,\n",
    "\"Aircraft_Movements\" real,\n",
    "\"Freight_Metric_Tonnes\" real,\n",
    "PRIMARY KEY (\"Airport_ID\")\n",
    ");\n",
    "\n",
    "CREATE TABLE `airport_aircraft` (\n",
    "\"ID\" int,\n",
    "\"Airport_ID\" int,\n",
    "\"Aircraft_ID\" int,\n",
    "PRIMARY KEY (\"Airport_ID\",\"Aircraft_ID\"),\n",
    "FOREIGN KEY (\"Airport_ID\") REFERENCES `airport`(`Airport_ID`),\n",
    "FOREIGN KEY (\"Aircraft_ID\") REFERENCES `aircraft`(`Aircraft_ID`)\n",
    ");\n",
    "\n",
    "### Answer\n",
    "Given the database schema, here is the SQLite query that answers [QUESTION]{question}[/QUESTION]\n",
    "[SQL]\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "architecture_prompt = \"\"\"\n",
    "### Task\n",
    "Generate a SQLite query to answer [QUESTION]{question}[/QUESTION]\n",
    "\n",
    "### Instructions\n",
    "- If you cannot answer the question with the available database schema, return 'I do not know'\n",
    "- Pay close attention to the given database schema, note on how they can join together\n",
    "- You do not need to generate your thought process but just the answer\n",
    "- Your answer should end with '[/SQL]'\n",
    "\n",
    "CREATE TABLE \"architect\" (\n",
    "\"id\" text,\n",
    "\"name\" text,\n",
    "\"nationality\" text,\n",
    "\"gender\" text,\n",
    "primary key(\"id\")\n",
    ");\n",
    "\n",
    "CREATE TABLE \"bridge\" (\n",
    "\"architect_id\" int,\n",
    "\"id\" int,\n",
    "\"name\" text,\n",
    "\"location\" text,\n",
    "\"length_meters\" real,\n",
    "\"length_feet\" real,\n",
    "primary key(\"id\"),\n",
    "foreign key (\"architect_id\" ) references `architect`(\"id\")\n",
    ");\n",
    "\n",
    "CREATE TABLE \"mill\" (\n",
    "\"architect_id\" int,\n",
    "\"id\" int,\n",
    "\"location\" text,\n",
    "\"name\" text,\n",
    "\"type\" text,\n",
    "\"built_year\" int,\n",
    "\"notes\" text,\n",
    "primary key (\"id\"),\n",
    "foreign key (\"architect_id\" ) references `architect`(\"id\")\n",
    ");\n",
    "\n",
    "### Answer\n",
    "Given the database schema, here is the SQLite query that answers [QUESTION]{question}[/QUESTION]\n",
    "[SQL]\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "cinema_prompt = \"\"\"\n",
    "### Task\n",
    "Generate a SQLite query to answer [QUESTION]{question}[/QUESTION]\n",
    "\n",
    "### Instructions\n",
    "- If you cannot answer the question with the available database schema, return 'I do not know'\n",
    "- Pay close attention to the given database schema, note on how they can join together\n",
    "- You do not need to generate your thought process but just the answer\n",
    "- Your answer should end with '[/SQL]'\n",
    "\n",
    "CREATE TABLE \"film\" (\n",
    "\"Film_ID\" int,\n",
    "\"Rank_in_series\" int,\n",
    "\"Number_in_season\" int,\n",
    "\"Title\" text,\n",
    "\"Directed_by\" text,\n",
    "\"Original_air_date\" text,\n",
    "\"Production_code\" text,\n",
    "PRIMARY KEY (\"Film_ID\")\n",
    ");\n",
    "\n",
    "CREATE TABLE \"cinema\" (\n",
    "\"Cinema_ID\" int,\n",
    "\"Name\" text,\n",
    "\"Openning_year\" int,\n",
    "\"Capacity\" int,\n",
    "\"Location\" text,\n",
    "PRIMARY KEY (\"Cinema_ID\"));\n",
    "\n",
    "CREATE TABLE \"schedule\" (\n",
    "\"Cinema_ID\" int,\n",
    "\"Film_ID\" int,\n",
    "\"Date\" text,\n",
    "\"Show_times_per_day\" int,\n",
    "\"Price\" float,\n",
    "PRIMARY KEY (\"Cinema_ID\",\"Film_ID\"),\n",
    "FOREIGN KEY (`Film_ID`) REFERENCES `film`(`Film_ID`),\n",
    "FOREIGN KEY (`Cinema_ID`) REFERENCES `cinema`(`Cinema_ID`)\n",
    ");\n",
    "\n",
    "### Answer\n",
    "Given the database schema, here is the SQLite query that answers [QUESTION]{question}[/QUESTION]\n",
    "[SQL]\n",
    "\"\"\"\n",
    "\n",
    "# Store each prompt and its corresponding DB name\n",
    "dbs = [\n",
    "    (\"department_management\", department_prompt),\n",
    "    (\"farm\", farm_prompt),\n",
    "    (\"aircraft\", aircraft_prompt),\n",
    "    (\"architecture\", architecture_prompt),\n",
    "    (\"cinema\", cinema_prompt),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Data\n",
    "\n",
    "* Spider Dataset\n",
    "\n",
    "* https://yale-lily.github.io/spider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Saved 110 training and 39 test samples.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from datasets import load_dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load Spider dataset\n",
    "ds = load_dataset(\"spider\")\n",
    "db_ids = [x[0] for x in dbs]\n",
    "\n",
    "# Create a mapping for easy access to the prompt\n",
    "prompt_map = {db_id: prompt for db_id, prompt in dbs}\n",
    "\n",
    "train_data = []\n",
    "test_data = []\n",
    "\n",
    "for db_id in db_ids:\n",
    "    subset = ds[\"train\"].filter(lambda x: x[\"db_id\"] == db_id)\n",
    "    questions = [entry[\"question\"] for entry in subset]\n",
    "    queries = [entry[\"query\"] for entry in subset]\n",
    "\n",
    "    entries = [{\"db_id\": db_id, \"question\": q, \"query\": sql} for q, sql in zip(questions, queries)]\n",
    "\n",
    "    # Split 75% train, 25% test\n",
    "    train_split, test_split = train_test_split(entries, test_size=0.25, random_state=42)\n",
    "\n",
    "    train_data.extend(train_split)\n",
    "    test_data.extend(test_split)\n",
    "\n",
    "# Format prompt with input-output pairs\n",
    "def format_training_example(entry):\n",
    "    prompt_template = prompt_map[entry[\"db_id\"]]\n",
    "    prompt = prompt_template.format(question=entry[\"question\"])\n",
    "    return {\n",
    "        \"prompt\": prompt,\n",
    "        \"completion\": entry[\"query\"] + \" [/SQL]\"\n",
    "    }\n",
    "\n",
    "# Apply formatting\n",
    "train_formatted = [format_training_example(e) for e in train_data]\n",
    "test_formatted = [format_training_example(e) for e in test_data]\n",
    "\n",
    "# Save to JSON\n",
    "with open(\"train_formatted.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(train_formatted, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "with open(\"test_formatted.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(test_formatted, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"âœ… Saved {len(train_formatted)} training and {len(test_formatted)} test samples.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 2,179,072 || all params: 1,779,267,072 || trainable%: 0.1225\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6b26e743fd54d228a804c8fedda0bad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19cf6902e05243ab9be0823cd45e9e00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56d4fbec58d64ec88a80e00c9b458965",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/110 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "592bcfce8e004a6d8c9cd93180902128",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/39 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "from peft import prepare_model_for_kbit_training, LoraConfig, get_peft_model\n",
    "import torch\n",
    "\n",
    "model_name = \"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\"\n",
    "cache_dir = \"E:/Data File/transformers.cache\"\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.float16\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, cache_dir=cache_dir, trust_remote_code=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    device_map=\"auto\",\n",
    "    quantization_config=bnb_config,\n",
    "    cache_dir=cache_dir,\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "model = prepare_model_for_kbit_training(model)\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\"\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, lora_config)\n",
    "model.print_trainable_parameters()\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "data_files = {\n",
    "    \"train\": \"train_formatted.json\",\n",
    "    \"test\": \"test_formatted.json\"\n",
    "}\n",
    "\n",
    "dataset = load_dataset(\"json\", data_files=data_files)\n",
    "\n",
    "def tokenize(batch):\n",
    "    return tokenizer(\n",
    "        batch[\"prompt\"],\n",
    "        text_pair=batch[\"completion\"],\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=512,\n",
    "        return_tensors=None\n",
    "    )\n",
    "\n",
    "tokenized = dataset.map(tokenize, batched=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\_dynamo\\eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='266' max='1400' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 266/1400 05:21 < 22:59, 0.82 it/s, Epoch 19/100]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.300500</td>\n",
       "      <td>1.852714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.831600</td>\n",
       "      <td>1.382503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.133800</td>\n",
       "      <td>0.891196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.804600</td>\n",
       "      <td>0.557452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.421300</td>\n",
       "      <td>0.368303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.324000</td>\n",
       "      <td>0.264648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.239100</td>\n",
       "      <td>0.212644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.178100</td>\n",
       "      <td>0.187654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.150700</td>\n",
       "      <td>0.172944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.133800</td>\n",
       "      <td>0.166426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.129500</td>\n",
       "      <td>0.159757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.115300</td>\n",
       "      <td>0.156117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.110700</td>\n",
       "      <td>0.153292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.097400</td>\n",
       "      <td>0.150666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.100400</td>\n",
       "      <td>0.149548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.085500</td>\n",
       "      <td>0.147452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.087800</td>\n",
       "      <td>0.148658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.080800</td>\n",
       "      <td>0.152024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.068300</td>\n",
       "      <td>0.153429</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\_dynamo\\eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\_dynamo\\eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\_dynamo\\eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\_dynamo\\eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\_dynamo\\eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\_dynamo\\eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\_dynamo\\eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\_dynamo\\eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\_dynamo\\eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\_dynamo\\eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\_dynamo\\eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\_dynamo\\eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\_dynamo\\eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\_dynamo\\eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\_dynamo\\eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\_dynamo\\eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\_dynamo\\eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\_dynamo\\eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=266, training_loss=0.41735757495227616, metrics={'train_runtime': 322.4337, 'train_samples_per_second': 34.116, 'train_steps_per_second': 4.342, 'total_flos': 9925377502740480.0, 'train_loss': 0.41735757495227616, 'epoch': 19.0})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import TrainingArguments, Trainer, DataCollatorForLanguageModeling\n",
    "from transformers import TrainerCallback\n",
    "from transformers import EarlyStoppingCallback\n",
    "\n",
    "class LossLoggerCallback(TrainerCallback):\n",
    "    def __init__(self):\n",
    "        self.train_logs = []\n",
    "        self.eval_logs = []\n",
    "\n",
    "    def on_log(self, args, state, control, logs=None, **kwargs):\n",
    "        if logs:\n",
    "            if \"loss\" in logs:\n",
    "                self.train_logs.append((state.global_step, logs[\"loss\"]))\n",
    "            if \"eval_loss\" in logs:\n",
    "                self.eval_logs.append((state.epoch, logs[\"eval_loss\"]))\n",
    "\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./lora-deepseek-1.5b\",\n",
    "    per_device_train_batch_size=4,\n",
    "    gradient_accumulation_steps=2,\n",
    "    num_train_epochs=100,\n",
    "    learning_rate=2e-4,\n",
    "    fp16=True,\n",
    "    logging_steps=10,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    "    greater_is_better=False,\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "loss_logger = LossLoggerCallback()\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized[\"train\"],\n",
    "    eval_dataset=tokenized[\"test\"],\n",
    "    data_collator=DataCollatorForLanguageModeling(tokenizer, mlm=False),\n",
    "    callbacks=[loss_logger, EarlyStoppingCallback(early_stopping_patience=3)]\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Extract data\n",
    "train_steps, train_losses = zip(*loss_logger.train_logs)\n",
    "eval_epochs, eval_losses = zip(*loss_logger.eval_logs)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(train_steps, train_losses, label=\"Training Loss\", marker='o')\n",
    "plt.plot(eval_epochs, eval_losses, label=\"Validation Loss\", marker='s')\n",
    "plt.xlabel(\"Step / Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training vs. Validation Loss\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./lora-deepseek-1.5b-adapter\\\\tokenizer_config.json',\n",
       " './lora-deepseek-1.5b-adapter\\\\special_tokens_map.json',\n",
       " './lora-deepseek-1.5b-adapter\\\\tokenizer.json')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained(\"./lora-deepseek-1.5b-adapter\")\n",
    "tokenizer.save_pretrained(\"./lora-deepseek-1.5b-adapter\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running evaluation on TEST SET only\n",
      "ðŸ” Evaluating department_management (4 questions)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "department_management:   0%|          | 0/4 [00:00<?, ?it/s]c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "department_management: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query failed: Execution failed on sql '\n",
      "SELECT D.department_ID,\n",
      "       D.Name,\n",
      "       COUNT(*)\n",
      "FROM department AS D\n",
      "JOIN manages AS M\n",
      "WHERE D.department_ID NOT EXISTS': near \"EXISTS\": syntax error\n",
      "âœ… Accuracy for department_management: 3/4 = 75.00%\n",
      "ðŸ” Evaluating farm (10 questions)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "farm:   0%|          | 0/10 [00:00<?, ?it/s]c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "farm:  10%|â–ˆ         | 1/10 [00:01<00:16,  1.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query failed: Execution failed on sql '\n",
      "SELECT T1.year,\n",
      "       T1official_name\n",
      "FROM city AS T1\n",
      "JOIN farm_competition AS T2 ON T1.city_id = T2.host_city_id\n",
      "JOIN competition_record AS T3 ON T2.competition_id = T3.competition_id\n",
      "WHERE T3.rank = 1': no such column: T1.year\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "farm:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:03<00:04,  1.45it/s]c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "farm:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:04<00:02,  1.71it/s]c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "farm:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [00:05<00:01,  1.89it/s]c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "farm: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:06<00:00,  1.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Accuracy for farm: 5/10 = 50.00%\n",
      "ðŸ” Evaluating aircraft (12 questions)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "aircraft:   0%|          | 0/12 [00:00<?, ?it/s]c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "aircraft:   8%|â–Š         | 1/12 [00:00<00:06,  1.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query failed: Execution failed on sql '\n",
      "SELECT *\n",
      "FROM airport\n",
      "WHERE INTMAX(International_Passengers) > 100000': no such function: INTMAX\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "aircraft:  17%|â–ˆâ–‹        | 2/12 [00:00<00:04,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query failed: Execution failed on sql '\n",
      "SELECT Description\n",
      "FROM aircraft\n",
      "WHERE Winning_Aircraft IS NOT NULL': no such column: Winning_Aircraft\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "aircraft:  25%|â–ˆâ–ˆâ–Œ       | 3/12 [00:01<00:04,  2.04it/s]c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "aircraft:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 4/12 [00:02<00:04,  1.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query failed: Execution failed on sql '\n",
      "SELECT Name\n",
      "FROM pilot\n",
      "WHERE Winning_Pilot NOT IN (\n",
      "  SELECT Winning_Pilot\n",
      "  FROM match WHERE Country LIKE '% Australia'': incomplete input\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "aircraft:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 5/12 [00:02<00:04,  1.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query failed: Execution failed on sql '\n",
      "SELECT Aircraft\n",
      "FROM aircraft\n",
      "WHERE Aircraft_ID NOT IN (\n",
      "  SELECT Winning_Aircraft\n",
      "  FROM match WHERE Date LIKE '% won%'': incomplete input\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "aircraft:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 6/12 [00:03<00:03,  1.57it/s]c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "aircraft:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 9/12 [00:04<00:01,  2.05it/s]c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "aircraft:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 10/12 [00:05<00:01,  1.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query failed: Execution failed on sql '\n",
      "SELECT Description\n",
      "FROM aircraft\n",
      "WHERE Airport_ID NOT IN\n",
      "    (SELECT Winning_Aircraft\n",
      "     FROM match\n",
      "     WHERE Round = 1\n",
      "       AND Winning_Pilot != '')': no such column: Airport_ID\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "aircraft:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 11/12 [00:06<00:00,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query failed: Execution failed on sql '\n",
      "SELECT INT(International_Passengers),\n",
      "       INT(Domestic_Passengers)\n",
      "FROM airport\n",
      "WHERE Airport_Name LIKE '% Heathrow%'': no such function: INT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "aircraft: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:06<00:00,  1.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query failed: Execution failed on sql '\n",
      "SELECT DISTINCT Labeled \"Location\"\n",
      "FROM `aircraft`\n",
      "WHERE \"Winning_Pilot\" NOT NULL': no such column: Labeled\n",
      "âœ… Accuracy for aircraft: 2/12 = 16.67%\n",
      "ðŸ” Evaluating architecture (5 questions)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "architecture:   0%|          | 0/5 [00:00<?, ?it/s]c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "architecture:  20%|â–ˆâ–ˆ        | 1/5 [00:00<00:01,  3.11it/s]c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "architecture:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:00<00:01,  2.67it/s]c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "architecture:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:01<00:01,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query failed: Execution failed on sql '\n",
      "SELECT DISTINCT n.name,\n",
      "                n.nationality\n",
      "FROM architect AS a\n",
      "JOIN mill AS m ON a.id = m.architect_id\n",
      "GROUP BY n.name,\n",
      "         n.nationality': no such column: n.name\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "architecture:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:02<00:00,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query failed: Execution failed on sql '\n",
      "SELECT count(*)\n",
      "FROM architect\n",
      "WHERE architect_id NOT EXISTS \"mill\" WHERE milllocation LIKE '% doesn't build%'': near \"EXISTS\": syntax error\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "architecture: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:02<00:00,  1.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query failed: Execution failed on sql '\n",
      "SELECT location\n",
      "FROM bridge\n",
      "WHERE architect_id LIKE '%Kolob Arch% OR '%Rainbow Bridge%': near \"Bridge\": syntax error\n",
      "âœ… Accuracy for architecture: 0/5 = 0.00%\n",
      "ðŸ” Evaluating cinema (8 questions)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cinema:   0%|          | 0/8 [00:00<?, ?it/s]c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "cinema:  12%|â–ˆâ–Ž        | 1/8 [00:01<00:09,  1.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query failed: Execution failed on sql '\n",
      "SELECT DISTINCT L LOCATION\n",
      "FROM cinema AS T1\n",
      "JOIN schedule AS T2 ON T1.Cinema_ID = T2.Cinema_ID\n",
      "JOIN film AS T3 ON T2.Film_ID = T3.Film_ID\n",
      "WHERE T3.Rank_in_series = 1000\n",
      "ORDER BY T1.Location</SQL>': near \"/\": syntax error\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "cinema:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:02<00:04,  1.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query failed: Execution failed on sql '\n",
      "SELECT name,\n",
      "       title, date, price\n",
      "FROM cinema\n",
      "JOIN schedule ON cinema.cinema_id = schedule.Cinema_ID\n",
      "GROUP BY name\n",
      "ORDER BY name': no such column: title\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "cinema:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:04<00:02,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query failed: Execution failed on sql '\n",
      "SELECT Name,\n",
      "FROM cinema\n",
      "WHERE cinema Name DESC\n",
      "ORDER BY Openning_year': near \"FROM\": syntax error\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "cinema:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:04<00:01,  1.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query failed: Execution failed on sql '\n",
      "SELECT Name,\n",
      "       Location\n",
      "FROM cinema\n",
      "WHERE capacity MAX': near \"MAX\": syntax error\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "cinema: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:06<00:00,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Accuracy for cinema: 4/8 = 50.00%\n",
      "\n",
      "ðŸ“Š Summary of Accuracy per Dataset:\n",
      " - department_management: 3/4 = 75.00%\n",
      " - farm: 5/10 = 50.00%\n",
      " - aircraft: 2/12 = 16.67%\n",
      " - architecture: 0/5 = 0.00%\n",
      " - cinema: 4/8 = 50.00%\n",
      "\n",
      "ðŸŽ¯ Final Accuracy: 14/39 = 35.90%\n",
      "Saved bad cases to bad_cases_lora-finetuned_deepseek-1.5b_test_cases.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "data = test_data\n",
    "\n",
    "import sqlite3\n",
    "import json\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import sqlparse\n",
    "\n",
    "# Path config\n",
    "def get_db_path(db_id):\n",
    "    base_dir = Path(r\"C:\\Users\\zly20\\OneDrive - The University of Western Ontario\\1B\\CS 9860 Advanced Machine Learning\\Final Project\\CS_9860_Final_Project\\data\")\n",
    "    return str(base_dir / f\"{db_id}.sqlite\")\n",
    "\n",
    "# Run SQL and return DataFrame\n",
    "def run_query_on_db(db_path, query):\n",
    "    try:\n",
    "        with sqlite3.connect(db_path) as conn:\n",
    "            result = pd.read_sql_query(query, conn)\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        print(\"Query failed:\", e)\n",
    "        return None\n",
    "\n",
    "# Accumulators\n",
    "correct = 0\n",
    "total = 0\n",
    "bad_cases = []\n",
    "\n",
    "# Per-dataset tracking\n",
    "correct_by_db = {}\n",
    "total_by_db = {}\n",
    "\n",
    "print(\"Running evaluation on TEST SET only\")\n",
    "\n",
    "# Loop through each database and use corresponding prompt\n",
    "for db_id, prompt_template in dbs:\n",
    "    subset = [item for item in data if item[\"db_id\"] == db_id]\n",
    "    db_path = get_db_path(db_id)\n",
    "\n",
    "    correct_local = 0\n",
    "    total_local = 0\n",
    "\n",
    "    def generate_query(question):\n",
    "        prompt = prompt_template.format(question=question)\n",
    "        inputs = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "        generated_ids = model.generate(\n",
    "            **inputs,\n",
    "            num_return_sequences=1,\n",
    "            eos_token_id=tokenizer.eos_token_id,\n",
    "            pad_token_id=tokenizer.eos_token_id,\n",
    "            max_new_tokens=168,\n",
    "            do_sample=False,\n",
    "            num_beams=1,\n",
    "        )\n",
    "        outputs = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)\n",
    "        return sqlparse.format(outputs[0].split(\"[SQL]\")[1].split(\"[/SQL]\")[0], reindent=True)\n",
    "\n",
    "    print(f\"ðŸ” Evaluating {db_id} ({len(subset)} questions)\")\n",
    "    for item in tqdm(subset, desc=f\"{db_id}\"):\n",
    "        question = item[\"question\"]\n",
    "        gold_query = item[\"query\"]\n",
    "\n",
    "        try:\n",
    "            pred_query = generate_query(question)\n",
    "\n",
    "            gold_result = run_query_on_db(db_path, gold_query)\n",
    "            pred_result = run_query_on_db(db_path, pred_query)\n",
    "\n",
    "            if gold_result is not None and pred_result is not None:\n",
    "                if gold_result.equals(pred_result):\n",
    "                    correct += 1\n",
    "                    correct_local += 1\n",
    "                else:\n",
    "                    bad_cases.append({\n",
    "                        \"db_id\": db_id,\n",
    "                        \"question\": question,\n",
    "                        \"gold_query\": gold_query,\n",
    "                        \"pred_query\": pred_query,\n",
    "                        \"error_type\": \"Mismatch\",\n",
    "                        \"gold_result\": gold_result.to_string(index=False),\n",
    "                        \"pred_result\": pred_result.to_string(index=False)\n",
    "                    })\n",
    "            else:\n",
    "                bad_cases.append({\n",
    "                    \"db_id\": db_id,\n",
    "                    \"question\": question,\n",
    "                    \"gold_query\": gold_query,\n",
    "                    \"pred_query\": pred_query,\n",
    "                    \"error_type\": \"ExecutionError\",\n",
    "                    \"gold_result\": str(gold_result),\n",
    "                    \"pred_result\": str(pred_result)\n",
    "                })\n",
    "\n",
    "            total += 1\n",
    "            total_local += 1\n",
    "\n",
    "        except Exception as e:\n",
    "            bad_cases.append({\n",
    "                \"db_id\": db_id,\n",
    "                \"question\": question,\n",
    "                \"gold_query\": gold_query,\n",
    "                \"pred_query\": \"N/A\",\n",
    "                \"error_type\": f\"Exception: {str(e)}\",\n",
    "                \"gold_result\": \"N/A\",\n",
    "                \"pred_result\": \"N/A\"\n",
    "            })\n",
    "            total += 1\n",
    "            total_local += 1\n",
    "            continue\n",
    "\n",
    "    correct_by_db[db_id] = correct_local\n",
    "    total_by_db[db_id] = total_local\n",
    "    print(f\"âœ… Accuracy for {db_id}: {correct_local}/{total_local} = {correct_local / total_local:.2%}\")\n",
    "\n",
    "output_filename = \"bad_cases_lora-finetuned_deepseek-1.5b_test_cases.json\"\n",
    "\n",
    "with open(output_filename, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump({\n",
    "        \"model_name\": \"lora-finetuned_deepseek-1.5b\",\n",
    "        \"final_accuracy\": correct / total,\n",
    "        \"per_dataset_accuracy\": {\n",
    "            db_id: correct_by_db[db_id] / total_by_db[db_id] for db_id in correct_by_db\n",
    "        },\n",
    "        \"bad_cases\": bad_cases\n",
    "    }, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(\"\\nðŸ“Š Summary of Accuracy per Dataset:\")\n",
    "for db_id in correct_by_db:\n",
    "    print(f\" - {db_id}: {correct_by_db[db_id]}/{total_by_db[db_id]} = {correct_by_db[db_id] / total_by_db[db_id]:.2%}\")\n",
    "\n",
    "print(f\"\\nðŸŽ¯ Final Accuracy: {correct}/{total} = {correct / total:.2%}\")\n",
    "print(f\"Saved bad cases to {output_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance on Entire Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\accelerate\\utils\\modeling.py:1536: UserWarning: Current model requires 256 bytes of buffer for offloaded layers, which seems does not fit any GPU's remaining memory. If you are experiencing a OOM later, please consider using offload_buffers=True.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ” Evaluating department_management (16 questions)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "department_management:   0%|          | 0/16 [00:00<?, ?it/s]c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "department_management:  19%|â–ˆâ–‰        | 3/16 [00:01<00:06,  1.97it/s]c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "department_management:  25%|â–ˆâ–ˆâ–Œ       | 4/16 [00:01<00:05,  2.20it/s]c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "department_management:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 7/16 [00:03<00:04,  2.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query failed: Execution failed on sql '\n",
      "SELECT DISTINCT Creation\n",
      "FROM department\n",
      "WHERE management(TEMPERARY_ID = 'Alabama')': no such function: management\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "department_management:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 8/16 [00:03<00:04,  1.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query failed: Execution failed on sql '\n",
      "SELECT born_state\n",
      "FROM head\n",
      "WHERE head_id NOT IN\n",
      "    (SELECT head_id\n",
      "     FROM management)\n",
      "ORDER BY born_state ASC</SQL>': near \"<\": syntax error\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "department_management:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 9/16 [00:05<00:05,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query failed: Execution failed on sql '\n",
      "SELECT D1 creation\n",
      "FROM department AS D1\n",
      "JOIN head AS H ON D1.department_ID = H.department_ID\n",
      "JOIN management AS M ON D1.department_ID = M.department_ID\n",
      "JOIN M temporary_acting ON Mtemporary_acting = 'Most'\n",
      "JOIN management ON COUNT(*) = 1': no such table: M\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "department_management:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 10/16 [00:05<00:04,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query failed: Execution failed on sql '\n",
      "SELECT name,\n",
      "       temp acting\n",
      "FROM management\n",
      "WHERE\n",
      "  temporary acting = 'Yes'': near \"acting\": syntax error\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "department_management:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 11/16 [00:06<00:03,  1.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query failed: Execution failed on sql '\n",
      "SELECT COUNT(DISTINCT temp_acting)\n",
      "FROM management': no such column: temp_acting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "department_management:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 13/16 [00:07<00:01,  1.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query failed: Execution failed on sql '\n",
      "SELECT DISTINCT age\n",
      "FROM head\n",
      "WHERE acting = 'Yes'': no such column: acting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "department_management:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 14/16 [00:08<00:01,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query failed: Execution failed on sql '\n",
      "SELECT b.born_state\n",
      "FROM department AS b\n",
      "JOIN management AS m ON b.department_id = 109\n",
      "JOIN head AS h ON m.head_id = 33\n",
      "AND h.department_id = 109\n",
      "ORDER BY b.born_state': no such column: b.born_state\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "department_management:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 15/16 [00:09<00:00,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query failed: Execution failed on sql '\n",
      "SELECT D.department_ID,\n",
      "       D.Name,\n",
      "       COUNT(*)\n",
      "FROM department AS D\n",
      "JOIN manages AS M\n",
      "WHERE D.department_ID NOT EXISTS': near \"EXISTS\": syntax error\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "department_management: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:09<00:00,  1.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query failed: Execution failed on sql '\n",
      "SELECT h.head_ID,\n",
      "       h.name\n",
      "FROM head\n",
      "WHERE t.name LIKE '%Ha%'': no such column: h.head_ID\n",
      "âœ… Accuracy for department_management: 5/16 = 31.25%\n",
      "ðŸ” Evaluating farm (40 questions)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "farm:   0%|          | 0/40 [00:00<?, ?it/s]c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "farm:   5%|â–Œ         | 2/40 [00:00<00:09,  3.83it/s]c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "farm:  10%|â–ˆ         | 4/40 [00:02<00:24,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query failed: Execution failed on sql '\n",
      "SELECT T1.Total_Horses\n",
      "FROM farm AS T1\n",
      "JOIN farm_competition AS T2 ON T1.Farm_ID = T2.Farm_ID\n",
      "ORDER BY T2.Year ASC': no such column: T2.Farm_ID\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "farm:  15%|â–ˆâ–Œ        | 6/40 [00:03<00:20,  1.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query failed: Execution failed on sql '\n",
      "SELECT Official_Name\n",
      "FROM city\n",
      "WHERE Hosts NOT LIKE 'Aliens'': no such column: Hosts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "farm:  18%|â–ˆâ–Š        | 7/40 [00:03<00:18,  1.76it/s]c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "farm:  22%|â–ˆâ–ˆâ–Ž       | 9/40 [00:04<00:17,  1.81it/s]c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "farm:  28%|â–ˆâ–ˆâ–Š       | 11/40 [00:08<00:38,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query failed: Execution failed on sql '\n",
      "SELECT MAX(Cows)\n",
      "FROM farm WHEREfarm_ID NOT IN\n",
      "  (SELECT Farmer_ID\n",
      "   FROM farm_competition\n",
      "   WHERE Theme = 'Cattle'\n",
      "     OR EXISTS\n",
      "       (SELECT Farmer_ID\n",
      "        FROM farm_competition\n",
      "        WHERE Theme = 'Horses'\n",
      "          OR EXISTS\n",
      "            (SELECT Farmer_ID\n",
      "             FROM farm_competition\n",
      "             WHERE Theme = 'Dogs'\n",
      "               OR EXISTS\n",
      "                 (SELECT Farmer_ID\n",
      "                  FROM farm_competition\n",
      "                  WHERE Theme = 'Rats'))))': near \"IN\": syntax error\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "farm:  30%|â–ˆâ–ˆâ–ˆ       | 12/40 [00:09<00:31,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query failed: Execution failed on sql '\n",
      "SELECT MAX(Cows)\n",
      "FROM farm\n",
      "WHERE Farmer_ID NOT  NULL\n",
      "  SELECT MIN(Cows)\n",
      "  FROM farm WHERE Farmer_ID NOT  NULL': near \"SELECT\": syntax error\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "farm:  32%|â–ˆâ–ˆâ–ˆâ–Ž      | 13/40 [00:09<00:23,  1.13it/s]c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "farm:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 14/40 [00:09<00:18,  1.41it/s]c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "farm:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 19/40 [00:12<00:16,  1.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query failed: Execution failed on sql '\n",
      "SELECT T1.Year,\n",
      "       T1.Official_Name\n",
      "FROM city AS T1\n",
      "JOIN farm_competition AS T2 ON T1.City_ID = T2.Host_city_ID\n",
      "ORDER BY T1.Official_Name ASC\n",
      "LIMIT 1': no such column: T1.Year\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "farm:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 20/40 [00:14<00:18,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query failed: Execution failed on sql '\n",
      "SELECT T1.year,\n",
      "       T1official_name\n",
      "FROM city AS T1\n",
      "JOIN farm_competition AS T2 ON T1.city_id = T2.host_city_id\n",
      "JOIN competition_record AS T3 ON T2.competition_id = T3.competition_id\n",
      "WHERE T3.rank = 1': no such column: T1.year\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "farm:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 21/40 [00:14<00:14,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query failed: Execution failed on sql '\n",
      "SELECT Official_Name\n",
      "FROM city\n",
      "WHERE Hosts > 1': no such column: Hosts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "farm:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 22/40 [00:14<00:11,  1.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query failed: Execution failed on sql '\n",
      "SELECT Official_Name\n",
      "FROM city\n",
      "WHERE COUNT(Distinct Hosts) > 1': no such column: Hosts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "farm:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 24/40 [00:17<00:15,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query failed: Execution failed on sql '\n",
      "SELECT T1.Status\n",
      "FROM city AS T1\n",
      "JOIN farm_competition AS T2 ON T1.City_ID = T2.Host_city_ID\n",
      "GROUP BY T1.City_ID\n",
      "ORDER BY COUNT(T2 competection_ID) DESC\n",
      "LIMIT 1': near \"competection_ID\": syntax error\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "farm:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 25/40 [00:18<00:14,  1.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query failed: Execution failed on sql '\n",
      "SELECT T1.Theme\n",
      "FROM city AS T1\n",
      "WHERE T2.Host_city_ID = 111111\n",
      "  AND T2 POPULATION > 1000': near \"POPULATION\": syntax error\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "farm:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 26/40 [00:19<00:13,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query failed: Execution failed on sql '\n",
      "SELECT T1.Theme\n",
      "FROM city AS T1\n",
      "WHERE T2.Host_city_ID\n",
      "  FROM city AS T2 WHERE T2.Host_city_ID IN\n",
      "    (SELECT City_ID\n",
      "     FROM city\n",
      "     WHERE Area_km_2 > 10000)': near \"FROM\": syntax error\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "farm:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 27/40 [00:19<00:10,  1.20it/s]c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "farm:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 28/40 [00:20<00:08,  1.44it/s]c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "farm:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 31/40 [00:22<00:07,  1.21it/s]c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "farm:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 32/40 [00:22<00:05,  1.43it/s]c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "farm:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 33/40 [00:23<00:04,  1.42it/s]c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "farm:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 34/40 [00:24<00:04,  1.42it/s]c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "farm:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 35/40 [00:25<00:03,  1.36it/s]c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "farm:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 36/40 [00:25<00:02,  1.40it/s]c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "farm:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 39/40 [00:27<00:00,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query failed: Execution failed on sql '\n",
      "SELECT census_rank\n",
      "FROM city\n",
      "WHERE status != 'Village'': no such column: census_rank\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "farm: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:27<00:00,  1.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Accuracy for farm: 17/40 = 42.50%\n",
      "ðŸ” Evaluating aircraft (46 questions)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "aircraft:   2%|â–         | 1/46 [00:00<00:14,  3.09it/s]c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "aircraft:   4%|â–         | 2/46 [00:00<00:13,  3.16it/s]c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "aircraft:   7%|â–‹         | 3/46 [00:00<00:12,  3.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query failed: Execution failed on sql '\n",
      "SELECT A Description\n",
      "FROM aircraft': no such column: A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "aircraft:   9%|â–Š         | 4/46 [00:01<00:19,  2.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query failed: Execution failed on sql '\n",
      "SELECT Description\n",
      "FROM aircraft\n",
      "WHERE Airport_ID NOT IN\n",
      "    (SELECT Winning_Aircraft\n",
      "     FROM match\n",
      "     WHERE Round = 1\n",
      "       AND Winning_Pilot != '')': no such column: Airport_ID\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "aircraft:  13%|â–ˆâ–Ž        | 6/46 [00:02<00:21,  1.86it/s]c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "aircraft:  15%|â–ˆâ–Œ        | 7/46 [00:03<00:23,  1.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query failed: Execution failed on sql '\n",
      "SELECT INT(International_Passengers),\n",
      "       INT(Domestic_Passengers)\n",
      "FROM airport\n",
      "WHERE Airport_Name LIKE '% Heathrow%'': no such function: INT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "aircraft:  17%|â–ˆâ–‹        | 8/46 [00:03<00:20,  1.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query failed: Execution failed on sql '\n",
      "SELECT Count(*)\n",
      "FROM airport\n",
      "WHERE Airport_Name LIKE '%London Heathrow%\"': unrecognized token: \"'%London Heathrow%\"\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "aircraft:  20%|â–ˆâ–‰        | 9/46 [00:04<00:19,  1.93it/s]c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "aircraft:  22%|â–ˆâ–ˆâ–       | 10/46 [00:05<00:26,  1.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query failed: Execution failed on sql '\n",
      "SELECT DISTINCT D.Domestic_Passengers\n",
      "FROM airport AS A\n",
      "JOIN PI AS PI\n",
      "JOIN airport_aircraft AS AA ON A.Aircraft_ID = AA.Aircraft\n",
      "GROUP BY A.Aircraft\n",
      "ORDER BY A.Domestic_Passengers ASC': no such table: PI\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "aircraft:  24%|â–ˆâ–ˆâ–       | 11/46 [00:06<00:27,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query failed: Execution failed on sql '\n",
      "SELECT MAX(Transit_Passengers)\n",
      "FROM airport\n",
      "WHERE Airport_Name LIKE '% transit%'\n",
      "  SELECT MIN(Transit_Passengers)\n",
      "  FROM airport WHERE Airport_Name LIKE '% transit%'': near \"SELECT\": syntax error\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "aircraft:  26%|â–ˆâ–ˆâ–Œ       | 12/46 [00:07<00:33,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query failed: Execution failed on sql '\n",
      "SELECT MIN(Total_Passengers)\n",
      "FROM airport AS A\n",
      "JOIN PI AS PI ON A.AIRPORT_ID = PI.AIRPORT_ID\n",
      "SELECT MAX(Total_Passengers)\n",
      "FROM airport AS A\n",
      "JOIN PI AS PI ON A.AIRPORT_ID = A.AIRPORT_ID': near \"SELECT\": syntax error\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "aircraft:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 19/46 [00:10<00:13,  1.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query failed: Execution failed on sql '\n",
      "SELECT Aircraft\n",
      "FROM airport_aircraft\n",
      "WHERE Airport_ID LIKE '%London Gatwick%'': no such column: Aircraft\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "aircraft:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 20/46 [00:11<00:13,  1.88it/s]c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "aircraft:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 21/46 [00:12<00:18,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query failed: Execution failed on sql '\n",
      "SELECT Description\n",
      "FROM aircraft\n",
      "WHERE Airport_ID REFERENCES airport WHERE airport .Total_Passengers GREATER THAN 1000000': near \"REFERENCES\": syntax error\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "aircraft:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 22/46 [00:13<00:21,  1.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query failed: Execution failed on sql '\n",
      "SELECT A.Aircraft\n",
      "FROM aircraft AS A\n",
      "WHERE A.Aircraft_ID IN\n",
      "  SELECT\n",
      "  SELECT W.Aircraft\n",
      "  FROM match AS M WHERE M.Finning_Pilot_ID = '3'\n",
      "  FROM match': near \"SELECT\": syntax error\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "aircraft:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 23/46 [00:14<00:18,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query failed: Execution failed on sql '\n",
      "SELECT avg(Total_Passengers)\n",
      "FROM airport\n",
      "WHERE airport_aircraft(\"Robinson R-22\")': no such function: airport_aircraft\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "aircraft:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24/46 [00:15<00:20,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query failed: Execution failed on sql '\n",
      "SELECT avg(Total_Passengers)\n",
      "FROM airport\n",
      "WHERE airport_aircraft('Robinson R-22') = T Woodward PRIMARY KEY (Total_Passengers)': near \"Woodward\": syntax error\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "aircraft:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/46 [00:16<00:17,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query failed: Execution failed on sql '\n",
      "SELECT DISTINCT Labeled \"Location\"\n",
      "FROM `aircraft`\n",
      "WHERE \"Winning_Pilot\" NOT NULL': no such column: Labeled\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "aircraft:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 26/46 [00:16<00:13,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query failed: Execution failed on sql '\n",
      "SELECT Description\n",
      "FROM aircraft\n",
      "WHERE Winning_Aircraft IS NOT NULL': no such column: Winning_Aircraft\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "aircraft:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 27/46 [00:17<00:12,  1.57it/s]c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "aircraft:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 28/46 [00:17<00:10,  1.64it/s]c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "aircraft:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 29/46 [00:18<00:10,  1.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query failed: Execution failed on sql '\n",
      "SELECT Aircraft\n",
      "FROM aircraft\n",
      "JOIN MATCH ON aircraft.Aircraft_ID WITH GROUPS\n",
      "ORDER BY COUNT(*)\n",
      "FROM match': near \"WITH\": syntax error\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "aircraft:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 30/46 [00:19<00:13,  1.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query failed: Execution failed on sql '\n",
      "SELECT Name,\n",
      "       COUNT(Distinctawin)\n",
      "FROM aircraft\n",
      "WHERE aircraft.Aircraft_ID NOT IN\n",
      "    (SELECT A.Aircraft_ID\n",
      "     FROM match\n",
      "     WHERE match.Winning_Aircraft NOT IN\n",
      "         (SELECT airport.aircraft\n",
      "          FROM airport\n",
      "          WHERE airport.Airport_Name LIKE ' %))': unrecognized token: \"' %))\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "aircraft:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 33/46 [00:20<00:07,  1.84it/s]c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "aircraft:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 34/46 [00:21<00:08,  1.40it/s]c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "aircraft:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 35/46 [00:22<00:07,  1.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query failed: Execution failed on sql '\n",
      "SELECT Aircraft\n",
      "FROM aircraft\n",
      "WHERE pilot_id NOT IN\n",
      "    (SELECT Winning_Pilot\n",
      "     FROM match)': no such column: pilot_id\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "aircraft:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 36/46 [00:23<00:06,  1.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query failed: Execution failed on sql '\n",
      "SELECT Aircraft\n",
      "FROM aircraft\n",
      "WHERE Aircraft_ID NOT IN (\n",
      "  SELECT Winning_Aircraft\n",
      "  FROM match WHERE Date LIKE '% won%'': incomplete input\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "aircraft:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 37/46 [00:23<00:05,  1.70it/s]c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "aircraft:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 38/46 [00:26<00:09,  1.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query failed: Execution failed on sql '\n",
      "SELECT A.Aircraft\n",
      "FROM aircraft AS A\n",
      "WHERE A.Aircraft_ID IN (\n",
      "  SELECT A.Aircraft_ID\n",
      "  FROM airport AS i1\n",
      "  JOIN airport_aircraft AS a1 ON A.Aircraft_ID IN\n",
      "    (SELECT DISTINCT A.Aircraft_ID\n",
      "     FROM airport_aircraft AS ai1\n",
      "     JOIN airport AS i2 ON i2.Airport_ID = ai1.Aircraft_ID\n",
      "     WHERE i2.Airport_Name LIKE '% Heathrow%'\n",
      "       AND i2.Airport_Name LIKE '% Gatwick%')\n",
      "  FROM airport AS i1': near \"FROM\": syntax error\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "aircraft:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/46 [00:26<00:07,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query failed: Execution failed on sql '\n",
      "SELECT Name\n",
      "FROM airport\n",
      "WHERE INTMAX(International_Passengers) IS MAX': no such column: Name\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "aircraft:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 40/46 [00:27<00:05,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query failed: Execution failed on sql '\n",
      "SELECT *\n",
      "FROM airport\n",
      "WHERE INTMAX(International_Passengers) > 100000': no such function: INTMAX\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "aircraft:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 41/46 [00:28<00:04,  1.21it/s]c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "aircraft:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 42/46 [00:28<00:03,  1.27it/s]c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "aircraft:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 43/46 [00:29<00:02,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query failed: Execution failed on sql '\n",
      "SELECT Name,\n",
      "       Age\n",
      "FROM pilot WHEREå¹´é¾„ < (\n",
      "SELECT MAX(å¹´é¾„)\n",
      "FROM pilot\n",
      "WHERE Winning_Pilot NOT NULL': near \"<\": syntax error\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "aircraft:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 44/46 [00:31<00:02,  1.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query failed: Execution failed on sql '\n",
      "SELECT T1.Age,\n",
      "       T1.Name\n",
      "FROM pilot AS T1\n",
      "WHERE T2.Aircraft_ID = 3\n",
      "  AND T2.Pilot_ID = 3\n",
      "ORDER BY T1.Age IN\n",
      "  (SELECT MIN(Age)\n",
      "   FROM pilot)\n",
      "LIMIT 1': no such column: T2.Aircraft_ID\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "aircraft:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 45/46 [00:32<00:01,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query failed: Execution failed on sql '\n",
      "SELECT Name\n",
      "FROM pilot\n",
      "WHERE Winning_Pilot NOT IN (\n",
      "  SELECT Winning_Pilot\n",
      "  FROM match WHERE Country LIKE '% Australia'': incomplete input\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "aircraft: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 46/46 [00:33<00:00,  1.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query failed: Execution failed on sql '\n",
      "SELECT Name\n",
      "FROM pilot\n",
      "WHERE winning_aircraft NOT IN\n",
      "    (SELECT Winning_Aircraft\n",
      "     FROM match\n",
      "     WHERE date LIKE '% won'\n",
      "     ORDER BY Winning_Aircraft ASC)': no such column: winning_aircraft\n",
      "âœ… Accuracy for aircraft: 9/46 = 19.57%\n",
      "ðŸ” Evaluating architecture (17 questions)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "architecture:   0%|          | 0/17 [00:00<?, ?it/s]c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "architecture:   6%|â–Œ         | 1/17 [00:00<00:06,  2.51it/s]c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "architecture:  12%|â–ˆâ–        | 2/17 [00:00<00:06,  2.43it/s]c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "architecture:  18%|â–ˆâ–Š        | 3/17 [00:01<00:06,  2.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query failed: Execution failed on sql '\n",
      "SELECT MAX(length_meters)\n",
      "FROM bridge\n",
      "WHERE name = \"Architect A\"\"': unrecognized token: \"\"Architect A\"\"\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "architecture:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 6/17 [00:02<00:06,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query failed: Execution failed on sql '\n",
      "SELECT DISTINCT n.name,\n",
      "                n.nationality\n",
      "FROM architect AS a\n",
      "JOIN mill AS m ON a.id = m.architect_id\n",
      "GROUP BY n.name,\n",
      "         n.nationality': no such column: n.name\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "architecture:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 8/17 [00:04<00:05,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query failed: Execution failed on sql '\n",
      "SELECT DISTINCT t1.name\n",
      "FROM mill AS t2\n",
      "JOIN architect AS t3 ON t2.architect_id = t3.id\n",
      "WHERE t3.nationality IN ('American',\n",
      "                         'Canadian')': no such column: t1.name\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "architecture:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 9/17 [00:04<00:04,  1.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query failed: Execution failed on sql '\n",
      "SELECT id,\n",
      "       name\n",
      "FROM architect\n",
      "WHERE archict_id NOT NULL\n",
      "  AND COUNT(*) >= 3': no such column: archict_id\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "architecture:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 10/17 [00:05<00:05,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query failed: Execution failed on sql '\n",
      "SELECT T1.id,\n",
      "       T1.name,\n",
      "       T1.nationality\n",
      "FROM bridge AS T1\n",
      "JOIN mill AS T2 ON T1.id = T2.architect_id\n",
      "ORDER BY T2.id DESC\n",
      "LIMIT 1': no such column: T1.nationality\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "architecture:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 11/17 [00:06<00:04,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query failed: Execution failed on sql '\n",
      "SELECT id,\n",
      "       name,\n",
      "       gender\n",
      "FROM architect\n",
      "WHERE architect_id NOT IN (1,\n",
      "                           3)\n",
      "ORDER BY name ASC\n",
      "LIMIT 10': no such column: architect_id\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "architecture:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 12/17 [00:07<00:03,  1.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query failed: Execution failed on sql '\n",
      "SELECT location\n",
      "FROM bridge\n",
      "WHERE architect_id LIKE '%Kolob Arch% OR '%Rainbow Bridge%': near \"Bridge\": syntax error\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "architecture:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 13/17 [00:07<00:02,  1.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query failed: Execution failed on sql '\n",
      "SELECT L names\n",
      "FROM mill\n",
      "WHERE mill names LIKE '%Moulin%'': near \"names\": syntax error\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "architecture:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 14/17 [00:07<00:01,  1.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query failed: Execution failed on sql '\n",
      "SELECT DISTINCT name\n",
      "FROM bridge\n",
      "WHERE architect_id\n",
      "  FROM mill': near \"FROM\": syntax error\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "architecture:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 15/17 [00:08<00:01,  1.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query failed: Execution failed on sql '\n",
      "SELECT TOP 2 (%) AS Most Common\n",
      "FROM mill\n",
      "GROUP BY mill\n",
      "WHERE count(mill) > 2': near \"2\": syntax error\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "architecture:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 16/17 [00:08<00:00,  1.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query failed: Execution failed on sql '\n",
      "SELECT count(*)\n",
      "FROM architect\n",
      "WHERE architect_id NOT EXISTS \"mill\" WHERE milllocation LIKE '% doesn't build%'': near \"EXISTS\": syntax error\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "architecture: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:09<00:00,  1.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query failed: Execution failed on sql '\n",
      "SELECT name\n",
      "FROM bridge\n",
      "WHERE architect_id LIKE '% American '%\n",
      "ORDER BY length_feet': near \"ORDER\": syntax error\n",
      "âœ… Accuracy for architecture: 3/17 = 17.65%\n",
      "ðŸ” Evaluating cinema (30 questions)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cinema:   0%|          | 0/30 [00:00<?, ?it/s]c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "cinema:   3%|â–Ž         | 1/30 [00:00<00:13,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query failed: Execution failed on sql '\n",
      "SELECT DISTINCT Location\n",
      "FROM cinema\n",
      "WHERE cinema capacities are NOT OVER 800': near \"capacities\": syntax error\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "cinema:   7%|â–‹         | 2/30 [00:01<00:17,  1.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query failed: Execution failed on sql '\n",
      "SELECT DISTINCT Location\n",
      "FROM cinema\n",
      "WHERE (OPENING_YEAR = 2010\n",
      "       AND OPENING_YEAR = 2011)': no such column: OPENING_YEAR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "cinema:  13%|â–ˆâ–Ž        | 4/30 [00:01<00:09,  2.73it/s]c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "cinema:  17%|â–ˆâ–‹        | 5/30 [00:02<00:11,  2.14it/s]c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "cinema:  20%|â–ˆâ–ˆ        | 6/30 [00:02<00:12,  1.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query failed: Execution failed on sql '\n",
      "SELECT Name,\n",
      "       Location\n",
      "FROM cinema\n",
      "WHERE capacity >\n",
      "    (SELECT MAX(capacity)\n",
      "     FROM schedule)': misuse of aggregate: MAX()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "cinema:  23%|â–ˆâ–ˆâ–Ž       | 7/30 [00:03<00:15,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query failed: Execution failed on sql '\n",
      "SELECT DISTINCT LOCATION\n",
      "FROM cinema\n",
      "WHERE cinema.name NOT IN (\n",
      "  SELECT film.name\n",
      "  FROM film WHERE film_id IN\n",
      "    (SELECT film.id\n",
      "     FROM schedule\n",
      "     WHERE schedule.cinema_id = 111111)': incomplete input\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "cinema:  30%|â–ˆâ–ˆâ–ˆ       | 9/30 [00:04<00:12,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query failed: Execution failed on sql '\n",
      "SELECT Name,\n",
      "FROM cinema\n",
      "WHERE cinema Name DESC\n",
      "ORDER BY Openning_year': near \"FROM\": syntax error\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "cinema:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 10/30 [00:05<00:11,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query failed: Execution failed on sql '\n",
      "SELECT Name,\n",
      "       Location\n",
      "FROM cinema\n",
      "WHERE capacity MAX': near \"MAX\": syntax error\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "cinema:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 12/30 [00:07<00:11,  1.51it/s]c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "cinema:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 13/30 [00:07<00:10,  1.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query failed: Execution failed on sql '\n",
      "SELECT LOCATION\n",
      "FROM cinema\n",
      "WHERE directed_by LIKE '%T%': unrecognized token: \"'%T%\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "cinema:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 14/30 [00:08<00:10,  1.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query failed: Execution failed on sql '\n",
      "SELECT LOCATION\n",
      "FROM cinema\n",
      "WHERE cinema directed by 'RIPER'\n",
      "  OR cinema directed by 'SHUTTLE'': near \"directed\": syntax error\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "cinema:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 15/30 [00:09<00:12,  1.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query failed: Execution failed on sql '\n",
      "SELECT DISTINCT LOCATION\n",
      "FROM cinema\n",
      "WHERE cinema directed by 'RIPETTA'\n",
      "  OR cinema directed by 'MANCIN'\n",
      "  OR cinema directed by 'GIOVANNE 1'': near \"directed\": syntax error\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "cinema:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 19/30 [00:11<00:06,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query failed: Execution failed on sql '\n",
      "SELECT DISTINCT D.title\n",
      "FROM film\n",
      "WHERE directed_by_id = D.directed_by\n",
      "ORDER BY D.title ASC': no such column: D.title\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "cinema:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 20/30 [00:11<00:05,  1.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query failed: Execution failed on sql '\n",
      "SELECT Dir_name\n",
      "FROM film\n",
      "GROUP BY Dir_name\n",
      "ORDER BY COUNT(*) DESC': no such column: Dir_name\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "cinema:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 21/30 [00:12<00:04,  2.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query failed: Execution failed on sql '\n",
      "SELECT COUNT(*)\n",
      "FROM schedule\n",
      "WHERE cinema_id NOT NULL\n",
      "  FROM cinema': near \"FROM\": syntax error\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "cinema:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 22/30 [00:13<00:04,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query failed: Execution failed on sql '\n",
      "SELECT T1.title,\n",
      "       MAX(T2.price)\n",
      "FROM schedule AS T1\n",
      "JOIN film AS T2 ON T1.film_id = T2.film_id': no such column: T1.title\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "cinema:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 23/30 [00:14<00:04,  1.47it/s]c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "cinema:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 24/30 [00:14<00:04,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query failed: Execution failed on sql '\n",
      "SELECT name,\n",
      "       title, date, price\n",
      "FROM cinema\n",
      "JOIN schedule ON cinema.cinema_id = schedule.Cinema_ID\n",
      "GROUP BY name\n",
      "ORDER BY name': no such column: title\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "cinema:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 25/30 [00:15<00:04,  1.19it/s]c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "cinema:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 26/30 [00:16<00:03,  1.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query failed: Execution failed on sql '\n",
      "SELECT T2.directed_by\n",
      "FROM schedule AS T1\n",
      "JOIN film AS T2 ON T1.Film_ID = T2.Film_ID\n",
      "GROUP BY T1.Film_ID\n",
      "ORDER BY COUNT(T2) DESC\n",
      "LIMIT 1': no such column: T2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "cinema:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 27/30 [00:17<00:02,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query failed: Execution failed on sql '\n",
      "SELECT LOCATION\n",
      "FROM cinema\n",
      "WHERE cinema-location LIKE '%Tues% OR %Thurs% OR %Fri%'': no such column: cinema\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "cinema:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 28/30 [00:19<00:02,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query failed: Execution failed on sql '\n",
      "SELECT DISTINCT L LOCATION\n",
      "FROM cinema AS T1\n",
      "JOIN schedule AS T2 ON T1.Cinema_ID = T2.Cinema_ID\n",
      "JOIN film AS T3 ON T2.Film_ID = T3.Film_ID\n",
      "WHERE T3.Rank_in_series = 1000\n",
      "ORDER BY T1.Location</SQL>': near \"/\": syntax error\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "cinema: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:19<00:00,  1.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Accuracy for cinema: 9/30 = 30.00%\n",
      "\n",
      "ðŸ“Š Summary of Accuracy per Dataset:\n",
      " - department_management: 5/16 = 31.25%\n",
      " - farm: 17/40 = 42.50%\n",
      " - aircraft: 9/46 = 19.57%\n",
      " - architecture: 3/17 = 17.65%\n",
      " - cinema: 9/30 = 30.00%\n",
      "\n",
      "ðŸŽ¯ Final Accuracy: 43/149 = 28.86%\n",
      "Saved bad cases to bad_cases_lora-finetuned_deepseek-1.5b.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from peft import PeftModel\n",
    "from transformers import AutoModelForCausalLM\n",
    "\n",
    "base_model = AutoModelForCausalLM.from_pretrained(model_name, cache_dir=cache_dir, device_map=\"auto\", trust_remote_code=True)\n",
    "model = PeftModel.from_pretrained(base_model, \"./lora-deepseek-1.5b-adapter\")\n",
    "model = model.to(\"cuda\")\n",
    "\n",
    "# Load Spider dataset\n",
    "ds = load_dataset(\"spider\")\n",
    "db_ids = [\"department_management\", \"farm\", \"aircraft\", \"architecture\", \"cinema\"]\n",
    "\n",
    "data = []\n",
    "\n",
    "for db_id in db_ids:\n",
    "    subset = ds[\"train\"].filter(lambda x: x[\"db_id\"] == db_id)\n",
    "    questions = [entry[\"question\"] for entry in subset]\n",
    "    queries = [entry[\"query\"] for entry in subset]\n",
    "\n",
    "    # Combine into (db_id, question, query) triplets\n",
    "    entries = [{\"db_id\": db_id, \"question\": q, \"query\": sql} for q, sql in zip(questions, queries)]\n",
    "\n",
    "    # Add to overall list\n",
    "    data.extend(entries)\n",
    "\n",
    "import sqlite3\n",
    "import json\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import sqlparse\n",
    "\n",
    "# Path config\n",
    "def get_db_path(db_id):\n",
    "    base_dir = Path(r\"C:\\Users\\zly20\\OneDrive - The University of Western Ontario\\1B\\CS 9860 Advanced Machine Learning\\Final Project\\CS_9860_Final_Project\\data\")\n",
    "    return str(base_dir / f\"{db_id}.sqlite\")\n",
    "\n",
    "# Run SQL and return DataFrame\n",
    "def run_query_on_db(db_path, query):\n",
    "    try:\n",
    "        with sqlite3.connect(db_path) as conn:\n",
    "            result = pd.read_sql_query(query, conn)\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        print(\"Query failed:\", e)\n",
    "        return None\n",
    "\n",
    "# Accumulators\n",
    "correct = 0\n",
    "total = 0\n",
    "bad_cases = []\n",
    "\n",
    "# Per-dataset tracking\n",
    "correct_by_db = {}\n",
    "total_by_db = {}\n",
    "\n",
    "# Loop through each database and use corresponding prompt\n",
    "for db_id, prompt_template in dbs:\n",
    "    subset = [item for item in data if item[\"db_id\"] == db_id]\n",
    "    db_path = get_db_path(db_id)\n",
    "\n",
    "    correct_local = 0\n",
    "    total_local = 0\n",
    "\n",
    "    def generate_query(question):\n",
    "        prompt = prompt_template.format(question=question)\n",
    "        inputs = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "        generated_ids = model.generate(\n",
    "            **inputs,\n",
    "            num_return_sequences=1,\n",
    "            eos_token_id=tokenizer.eos_token_id,\n",
    "            pad_token_id=tokenizer.eos_token_id,\n",
    "            max_new_tokens=168,\n",
    "            do_sample=False,\n",
    "            num_beams=1,\n",
    "        )\n",
    "        outputs = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)\n",
    "        return sqlparse.format(outputs[0].split(\"[SQL]\")[1].split(\"[/SQL]\")[0], reindent=True)\n",
    "\n",
    "    print(f\"ðŸ” Evaluating {db_id} ({len(subset)} questions)\")\n",
    "    for item in tqdm(subset, desc=f\"{db_id}\"):\n",
    "        question = item[\"question\"]\n",
    "        gold_query = item[\"query\"]\n",
    "\n",
    "        try:\n",
    "            pred_query = generate_query(question)\n",
    "\n",
    "            gold_result = run_query_on_db(db_path, gold_query)\n",
    "            pred_result = run_query_on_db(db_path, pred_query)\n",
    "\n",
    "            if gold_result is not None and pred_result is not None:\n",
    "                if gold_result.equals(pred_result):\n",
    "                    correct += 1\n",
    "                    correct_local += 1\n",
    "                else:\n",
    "                    bad_cases.append({\n",
    "                        \"db_id\": db_id,\n",
    "                        \"question\": question,\n",
    "                        \"gold_query\": gold_query,\n",
    "                        \"pred_query\": pred_query,\n",
    "                        \"error_type\": \"Mismatch\",\n",
    "                        \"gold_result\": gold_result.to_string(index=False),\n",
    "                        \"pred_result\": pred_result.to_string(index=False)\n",
    "                    })\n",
    "            else:\n",
    "                bad_cases.append({\n",
    "                    \"db_id\": db_id,\n",
    "                    \"question\": question,\n",
    "                    \"gold_query\": gold_query,\n",
    "                    \"pred_query\": pred_query,\n",
    "                    \"error_type\": \"ExecutionError\",\n",
    "                    \"gold_result\": str(gold_result),\n",
    "                    \"pred_result\": str(pred_result)\n",
    "                })\n",
    "\n",
    "            total += 1\n",
    "            total_local += 1\n",
    "\n",
    "        except Exception as e:\n",
    "            bad_cases.append({\n",
    "                \"db_id\": db_id,\n",
    "                \"question\": question,\n",
    "                \"gold_query\": gold_query,\n",
    "                \"pred_query\": \"N/A\",\n",
    "                \"error_type\": f\"Exception: {str(e)}\",\n",
    "                \"gold_result\": \"N/A\",\n",
    "                \"pred_result\": \"N/A\"\n",
    "            })\n",
    "            total += 1\n",
    "            total_local += 1\n",
    "            continue\n",
    "\n",
    "    correct_by_db[db_id] = correct_local\n",
    "    total_by_db[db_id] = total_local\n",
    "    print(f\"âœ… Accuracy for {db_id}: {correct_local}/{total_local} = {correct_local / total_local:.2%}\")\n",
    "\n",
    "output_filename = \"bad_cases_lora-finetuned_deepseek-1.5b.json\"\n",
    "\n",
    "with open(output_filename, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump({\n",
    "        \"model_name\": \"lora-finetuned_deepseek-1.5b\",\n",
    "        \"final_accuracy\": correct / total,\n",
    "        \"per_dataset_accuracy\": {\n",
    "            db_id: correct_by_db[db_id] / total_by_db[db_id] for db_id in correct_by_db\n",
    "        },\n",
    "        \"bad_cases\": bad_cases\n",
    "    }, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(\"\\nðŸ“Š Summary of Accuracy per Dataset:\")\n",
    "for db_id in correct_by_db:\n",
    "    print(f\" - {db_id}: {correct_by_db[db_id]}/{total_by_db[db_id]} = {correct_by_db[db_id] / total_by_db[db_id]:.2%}\")\n",
    "\n",
    "print(f\"\\nðŸŽ¯ Final Accuracy: {correct}/{total} = {correct / total:.2%}\")\n",
    "print(f\"Saved bad cases to {output_filename}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
