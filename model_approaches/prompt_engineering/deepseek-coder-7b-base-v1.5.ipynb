{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Data\n",
    "\n",
    "* Spider Dataset\n",
    "\n",
    "* https://yale-lily.github.io/spider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Load Spider dataset\n",
    "ds = load_dataset(\"spider\")\n",
    "db_ids = [\"department_management\", \"farm\", \"aircraft\", \"architecture\", \"cinema\"]\n",
    "\n",
    "data = []\n",
    "\n",
    "for db_id in db_ids:\n",
    "    subset = ds[\"train\"].filter(lambda x: x[\"db_id\"] == db_id)\n",
    "    questions = [entry[\"question\"] for entry in subset]\n",
    "    queries = [entry[\"query\"] for entry in subset]\n",
    "\n",
    "    # Combine into (db_id, question, query) triplets\n",
    "    entries = [{\"db_id\": db_id, \"question\": q, \"query\": sql} for q, sql in zip(questions, queries)]\n",
    "\n",
    "    # Add to overall list\n",
    "    data.extend(entries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# deepseek-coder-7b-base-v1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "17170956288\n",
      "C:\\Users\\zly20\\.cache\\huggingface\\hub\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3056b06c530a4bfba3063fa13adcdf9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/772 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zly20\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\huggingface_hub\\file_download.py:140: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in E:\\Data File\\transformers.cache\\models--deepseek-ai--deepseek-coder-7b-base-v1.5. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "faa0cdf0af534b0b936d0ce61a091d61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/4.61M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce948ec5c4ab4b6d902a36b2091674ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/621 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33750e844b3640c1b577a52fc5f46ece",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/22.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85f7b9db0ed64de0af50a5e4b00dd05e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a393da60f8234308a7c18219ef1de9b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00003.safetensors:   0%|          | 0.00/4.99G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df41c5377c32404a959f93f70a86e31b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00003.safetensors:   0%|          | 0.00/4.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7900eebdd5646e1afed3023acad0613",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00003.safetensors:   0%|          | 0.00/3.85G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8914154e8694d779b39213ae907efa7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "610428cf2dff4e92848408f8baedff4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/121 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sqlparse\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig, TRANSFORMERS_CACHE\n",
    "\n",
    "print(torch.cuda.is_available())\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "available_memory = torch.cuda.get_device_properties(0).total_memory\n",
    "print(available_memory)\n",
    "\n",
    "print(TRANSFORMERS_CACHE)\n",
    "\n",
    "model_name = \"deepseek-ai/deepseek-coder-7b-base-v1.5\"\n",
    "cache_dir = \"E:/Data File/transformers.cache\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name,cache_dir=cache_dir)\n",
    "\n",
    "if available_memory > 15e9:\n",
    "    # if you have atleast 15GB of GPU memory, run load the model in float16\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_name,\n",
    "        trust_remote_code=True,\n",
    "        torch_dtype=torch.float16,\n",
    "        device_map=\"auto\",\n",
    "        use_cache=True,\n",
    "        cache_dir=cache_dir\n",
    "    )\n",
    "else:\n",
    "    # else, load in 8 bits ‚Äì this is a bit slower\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_name,\n",
    "        trust_remote_code=True,\n",
    "        # torch_dtype=torch.float16,\n",
    "        load_in_8bit=True,\n",
    "        device_map=\"auto\",\n",
    "        use_cache=True,\n",
    "        cache_dir=cache_dir\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "department_prompt = \"\"\"\n",
    "### Task\n",
    "Generate a SQLite query to answer [QUESTION]{question}[/QUESTION]\n",
    "\n",
    "### Instructions\n",
    "- If you cannot answer the question with the available database schema, return 'I do not know'\n",
    "- Pay close attention to the given database schema, note on how they can join together\n",
    "- You do not need to generate your thought process but just the answer\n",
    "- Your answer should end with '[/SQL]'\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS \"department\" (\n",
    "\"Department_ID\" int,\n",
    "\"Name\" text,\n",
    "\"Creation\" text,\n",
    "\"Ranking\" int,\n",
    "\"Budget_in_Billions\" real,\n",
    "\"Num_Employees\" real,\n",
    "PRIMARY KEY (\"Department_ID\")\n",
    ");\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS \"head\" (\n",
    "\"head_ID\" int,\n",
    "\"name\" text,\n",
    "\"born_state\" text,\n",
    "\"age\" real,\n",
    "PRIMARY KEY (\"head_ID\")\n",
    ");\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS \"management\" (\n",
    "\"department_ID\" int,\n",
    "\"head_ID\" int,\n",
    "\"temporary_acting\" text,\n",
    "PRIMARY KEY (\"Department_ID\",\"head_ID\"),\n",
    "FOREIGN KEY (\"Department_ID\") REFERENCES `department`(\"Department_ID\"),\n",
    "FOREIGN KEY (\"head_ID\") REFERENCES `head`(\"head_ID\")\n",
    ");\n",
    "\n",
    "### Answer\n",
    "Given the database schema, here is the SQLite query that answers [QUESTION]{question}[/QUESTION]\n",
    "[SQL]\n",
    "\"\"\" \n",
    "\n",
    "\n",
    "farm_prompt = \"\"\"\n",
    "### Task\n",
    "Generate a SQLite query to answer [QUESTION]{question}[/QUESTION]\n",
    "\n",
    "### Instructions\n",
    "- If you cannot answer the question with the available database schema, return 'I do not know'\n",
    "- Pay close attention to the given database schema, note on how they can join together\n",
    "- You do not need to generate your thought process but just the answer\n",
    "- Your answer should end with '[/SQL]'\n",
    "\n",
    "CREATE TABLE \"city\" (\n",
    "\"City_ID\" int,\n",
    "\"Official_Name\" text,\n",
    "\"Status\" text,\n",
    "\"Area_km_2\" real,\n",
    "\"Population\" real,\n",
    "\"Census_Ranking\" text,\n",
    "PRIMARY KEY (\"City_ID\")\n",
    ");\n",
    "\n",
    "CREATE TABLE \"farm\" (\n",
    "\"Farm_ID\" int,\n",
    "\"Year\" int,\n",
    "\"Total_Horses\" real,\n",
    "\"Working_Horses\" real,\n",
    "\"Total_Cattle\" real,\n",
    "\"Oxen\" real,\n",
    "\"Bulls\" real,\n",
    "\"Cows\" real,\n",
    "\"Pigs\" real,\n",
    "\"Sheep_and_Goats\" real,\n",
    "PRIMARY KEY (\"Farm_ID\")\n",
    ");\n",
    "\n",
    "CREATE TABLE \"farm_competition\" (\n",
    "\"Competition_ID\" int,\n",
    "\"Year\" int,\n",
    "\"Theme\" text,\n",
    "\"Host_city_ID\" int,\n",
    "\"Hosts\" text,\n",
    "PRIMARY KEY (\"Competition_ID\"),\n",
    "FOREIGN KEY (`Host_city_ID`) REFERENCES `city`(`City_ID`)\n",
    ");\n",
    "\n",
    "\n",
    "CREATE TABLE \"competition_record\" (\n",
    "\"Competition_ID\" int,\n",
    "\"Farm_ID\" int,\n",
    "\"Rank\" int,\n",
    "PRIMARY KEY (\"Competition_ID\",\"Farm_ID\"),\n",
    "FOREIGN KEY (`Competition_ID`) REFERENCES `farm_competition`(`Competition_ID`),\n",
    "FOREIGN KEY (`Farm_ID`) REFERENCES `farm`(`Farm_ID`)\n",
    ");\n",
    "\n",
    "### Answer\n",
    "Given the database schema, here is the SQLite query that answers [QUESTION]{question}[/QUESTION]\n",
    "[SQL]\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "aircraft_prompt = \"\"\"\n",
    "### Task\n",
    "Generate a SQLite query to answer [QUESTION]{question}[/QUESTION]\n",
    "\n",
    "### Instructions\n",
    "- If you cannot answer the question with the available database schema, return 'I do not know'\n",
    "- Pay close attention to the given database schema, note on how they can join together\n",
    "- You do not need to generate your thought process but just the answer\n",
    "- Your answer should end with '[/SQL]'\n",
    "\n",
    "CREATE TABLE `pilot` (\n",
    "  `Pilot_Id` int(11) NOT NULL,\n",
    "  `Name` varchar(50) NOT NULL,\n",
    "  `Age` int(11) NOT NULL,\n",
    "  PRIMARY KEY (`Pilot_Id`)\n",
    ");\n",
    "\n",
    "CREATE TABLE `aircraft` (\n",
    "  \"Aircraft_ID\" int(11) NOT NULL,\n",
    "  \"Aircraft\" varchar(50) NOT NULL,\n",
    "  \"Description\" varchar(50) NOT NULL,\n",
    "  \"Max_Gross_Weight\" varchar(50) NOT NULL,\n",
    "  \"Total_disk_area\" varchar(50) NOT NULL,\n",
    "  \"Max_disk_Loading\" varchar(50) NOT NULL,\n",
    "  PRIMARY KEY (`Aircraft_ID`)\n",
    ");\n",
    "\n",
    "CREATE TABLE `match` (\n",
    "\"Round\" real,\n",
    "\"Location\" text,\n",
    "\"Country\" text,\n",
    "\"Date\" text,\n",
    "\"Fastest_Qualifying\" text,\n",
    "\"Winning_Pilot\" text,\n",
    "\"Winning_Aircraft\" text,\n",
    "PRIMARY KEY (\"Round\"),\n",
    "FOREIGN KEY (`Winning_Aircraft`) REFERENCES `aircraft`(`Aircraft_ID`),\n",
    "FOREIGN KEY (`Winning_Pilot`) REFERENCES `pilot`(`Pilot_Id`)\n",
    ");\n",
    "\n",
    "CREATE TABLE `airport` (\n",
    "\"Airport_ID\" int,\n",
    "\"Airport_Name\" text,\n",
    "\"Total_Passengers\" real,\n",
    "\"%_Change_2007\" text,\n",
    "\"International_Passengers\" real,\n",
    "\"Domestic_Passengers\" real,\n",
    "\"Transit_Passengers\" real,\n",
    "\"Aircraft_Movements\" real,\n",
    "\"Freight_Metric_Tonnes\" real,\n",
    "PRIMARY KEY (\"Airport_ID\")\n",
    ");\n",
    "\n",
    "CREATE TABLE `airport_aircraft` (\n",
    "\"ID\" int,\n",
    "\"Airport_ID\" int,\n",
    "\"Aircraft_ID\" int,\n",
    "PRIMARY KEY (\"Airport_ID\",\"Aircraft_ID\"),\n",
    "FOREIGN KEY (\"Airport_ID\") REFERENCES `airport`(`Airport_ID`),\n",
    "FOREIGN KEY (\"Aircraft_ID\") REFERENCES `aircraft`(`Aircraft_ID`)\n",
    ");\n",
    "\n",
    "### Answer\n",
    "Given the database schema, here is the SQLite query that answers [QUESTION]{question}[/QUESTION]\n",
    "[SQL]\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "architecture_prompt = \"\"\"\n",
    "### Task\n",
    "Generate a SQLite query to answer [QUESTION]{question}[/QUESTION]\n",
    "\n",
    "### Instructions\n",
    "- If you cannot answer the question with the available database schema, return 'I do not know'\n",
    "- Pay close attention to the given database schema, note on how they can join together\n",
    "- You do not need to generate your thought process but just the answer\n",
    "- Your answer should end with '[/SQL]'\n",
    "\n",
    "CREATE TABLE \"architect\" (\n",
    "\"id\" text,\n",
    "\"name\" text,\n",
    "\"nationality\" text,\n",
    "\"gender\" text,\n",
    "primary key(\"id\")\n",
    ");\n",
    "\n",
    "CREATE TABLE \"bridge\" (\n",
    "\"architect_id\" int,\n",
    "\"id\" int,\n",
    "\"name\" text,\n",
    "\"location\" text,\n",
    "\"length_meters\" real,\n",
    "\"length_feet\" real,\n",
    "primary key(\"id\"),\n",
    "foreign key (\"architect_id\" ) references `architect`(\"id\")\n",
    ");\n",
    "\n",
    "CREATE TABLE \"mill\" (\n",
    "\"architect_id\" int,\n",
    "\"id\" int,\n",
    "\"location\" text,\n",
    "\"name\" text,\n",
    "\"type\" text,\n",
    "\"built_year\" int,\n",
    "\"notes\" text,\n",
    "primary key (\"id\"),\n",
    "foreign key (\"architect_id\" ) references `architect`(\"id\")\n",
    ");\n",
    "\n",
    "### Answer\n",
    "Given the database schema, here is the SQLite query that answers [QUESTION]{question}[/QUESTION]\n",
    "[SQL]\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "cinema_prompt = \"\"\"\n",
    "### Task\n",
    "Generate a SQLite query to answer [QUESTION]{question}[/QUESTION]\n",
    "\n",
    "### Instructions\n",
    "- If you cannot answer the question with the available database schema, return 'I do not know'\n",
    "- Pay close attention to the given database schema, note on how they can join together\n",
    "- You do not need to generate your thought process but just the answer\n",
    "- Your answer should end with '[/SQL]'\n",
    "\n",
    "CREATE TABLE \"film\" (\n",
    "\"Film_ID\" int,\n",
    "\"Rank_in_series\" int,\n",
    "\"Number_in_season\" int,\n",
    "\"Title\" text,\n",
    "\"Directed_by\" text,\n",
    "\"Original_air_date\" text,\n",
    "\"Production_code\" text,\n",
    "PRIMARY KEY (\"Film_ID\")\n",
    ");\n",
    "\n",
    "CREATE TABLE \"cinema\" (\n",
    "\"Cinema_ID\" int,\n",
    "\"Name\" text,\n",
    "\"Openning_year\" int,\n",
    "\"Capacity\" int,\n",
    "\"Location\" text,\n",
    "PRIMARY KEY (\"Cinema_ID\"));\n",
    "\n",
    "CREATE TABLE \"schedule\" (\n",
    "\"Cinema_ID\" int,\n",
    "\"Film_ID\" int,\n",
    "\"Date\" text,\n",
    "\"Show_times_per_day\" int,\n",
    "\"Price\" float,\n",
    "PRIMARY KEY (\"Cinema_ID\",\"Film_ID\"),\n",
    "FOREIGN KEY (`Film_ID`) REFERENCES `film`(`Film_ID`),\n",
    "FOREIGN KEY (`Cinema_ID`) REFERENCES `cinema`(`Cinema_ID`)\n",
    ");\n",
    "\n",
    "### Answer\n",
    "Given the database schema, here is the SQLite query that answers [QUESTION]{question}[/QUESTION]\n",
    "[SQL]\n",
    "\"\"\"\n",
    "\n",
    "# Store each prompt and its corresponding DB name\n",
    "dbs = [\n",
    "    (\"department_management\", department_prompt),\n",
    "    (\"farm\", farm_prompt),\n",
    "    (\"aircraft\", aircraft_prompt),\n",
    "    (\"architecture\", architecture_prompt),\n",
    "    (\"cinema\", cinema_prompt),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Evaluating department_management (16 questions)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "department_management:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 10/16 [00:45<00:27,  4.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query failed: Execution failed on sql '\n",
      "SELECT department.Name,\n",
      "       department.Num_Employees\n",
      "FROM department\n",
      "JOIN management ON department.Department_ID = management.department_ID\n",
      "JOIN head ON management.head_ID = head.head_ID\n",
      "WHERE head.temporary_acting = 'Yes';': no such column: head.temporary_acting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "department_management: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [01:12<00:00,  4.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Accuracy for department_management: 5/16 = 31.25%\n",
      "üîç Evaluating farm (40 questions)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "farm: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 40/40 [03:02<00:00,  4.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Accuracy for farm: 19/40 = 47.50%\n",
      "üîç Evaluating aircraft (46 questions)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "aircraft:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 43/46 [03:20<00:13,  4.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query failed: Execution failed on sql '\n",
      "SELECT Name,\n",
      "       Age\n",
      "FROM pilot\n",
      "JOIN match ON pilot.Pilot_Id = match.Winning_Pilot\n",
      "WHERE match.Winning_Pilot =\n",
      "    (SELECT Winning_Pilot\n",
      "     FROM match\n",
      "     ORDER BY Age ASC\n",
      "     LIMIT 1);': no such column: Age\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "aircraft: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 46/46 [03:34<00:00,  4.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Accuracy for aircraft: 24/46 = 52.17%\n",
      "üîç Evaluating architecture (17 questions)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "architecture:  18%|‚ñà‚ñä        | 3/17 [00:13<01:02,  4.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query failed: Execution failed on sql '\n",
      "SELECT MAX(length_meters),\n",
      "       name\n",
      "FROM bridge\n",
      "JOIN architect ON bridge.architect_id = architect.id': ambiguous column name: name\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "architecture: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 17/17 [01:16<00:00,  4.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Accuracy for architecture: 10/17 = 58.82%\n",
      "üîç Evaluating cinema (30 questions)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cinema: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 30/30 [02:15<00:00,  4.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Accuracy for cinema: 16/30 = 53.33%\n",
      "\n",
      "üìä Summary of Accuracy per Dataset:\n",
      " - department_management: 5/16 = 31.25%\n",
      " - farm: 19/40 = 47.50%\n",
      " - aircraft: 24/46 = 52.17%\n",
      " - architecture: 10/17 = 58.82%\n",
      " - cinema: 16/30 = 53.33%\n",
      "\n",
      "üéØ Final Accuracy: 74/149 = 49.66%\n",
      "Saved bad cases to bad_cases_deepseek-ai_deepseek-coder-7b-base-v1.5.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import json\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import sqlparse\n",
    "\n",
    "# Path config\n",
    "def get_db_path(db_id):\n",
    "    base_dir = Path(r\"C:\\Users\\zly20\\OneDrive - The University of Western Ontario\\1B\\CS 9860 Advanced Machine Learning\\Final Project\\CS_9860_Final_Project\\data\")\n",
    "    return str(base_dir / f\"{db_id}.sqlite\")\n",
    "\n",
    "# Run SQL and return DataFrame\n",
    "def run_query_on_db(db_path, query):\n",
    "    try:\n",
    "        with sqlite3.connect(db_path) as conn:\n",
    "            result = pd.read_sql_query(query, conn)\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        print(\"Query failed:\", e)\n",
    "        return None\n",
    "\n",
    "# Accumulators\n",
    "correct = 0\n",
    "total = 0\n",
    "bad_cases = []\n",
    "\n",
    "# Per-dataset tracking\n",
    "correct_by_db = {}\n",
    "total_by_db = {}\n",
    "\n",
    "# Loop through each database and use corresponding prompt\n",
    "for db_id, prompt_template in dbs:\n",
    "    subset = [item for item in data if item[\"db_id\"] == db_id]\n",
    "    db_path = get_db_path(db_id)\n",
    "\n",
    "    correct_local = 0\n",
    "    total_local = 0\n",
    "\n",
    "    def generate_query(question):\n",
    "        prompt = prompt_template.format(question=question)\n",
    "        inputs = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "        generated_ids = model.generate(\n",
    "            **inputs,\n",
    "            num_return_sequences=1,\n",
    "            eos_token_id=tokenizer.eos_token_id,\n",
    "            pad_token_id=tokenizer.eos_token_id,\n",
    "            max_new_tokens=168,\n",
    "            do_sample=False,\n",
    "            num_beams=1,\n",
    "        )\n",
    "        outputs = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)\n",
    "        return sqlparse.format(outputs[0].split(\"[SQL]\")[1].split(\"[/SQL]\")[0], reindent=True)\n",
    "\n",
    "    print(f\"üîç Evaluating {db_id} ({len(subset)} questions)\")\n",
    "    for item in tqdm(subset, desc=f\"{db_id}\"):\n",
    "        question = item[\"question\"]\n",
    "        gold_query = item[\"query\"]\n",
    "\n",
    "        try:\n",
    "            pred_query = generate_query(question)\n",
    "\n",
    "            gold_result = run_query_on_db(db_path, gold_query)\n",
    "            pred_result = run_query_on_db(db_path, pred_query)\n",
    "\n",
    "            if gold_result is not None and pred_result is not None:\n",
    "                if gold_result.equals(pred_result):\n",
    "                    correct += 1\n",
    "                    correct_local += 1\n",
    "                else:\n",
    "                    bad_cases.append({\n",
    "                        \"db_id\": db_id,\n",
    "                        \"question\": question,\n",
    "                        \"gold_query\": gold_query,\n",
    "                        \"pred_query\": pred_query,\n",
    "                        \"error_type\": \"Mismatch\",\n",
    "                        \"gold_result\": gold_result.to_string(index=False),\n",
    "                        \"pred_result\": pred_result.to_string(index=False)\n",
    "                    })\n",
    "            else:\n",
    "                bad_cases.append({\n",
    "                    \"db_id\": db_id,\n",
    "                    \"question\": question,\n",
    "                    \"gold_query\": gold_query,\n",
    "                    \"pred_query\": pred_query,\n",
    "                    \"error_type\": \"ExecutionError\",\n",
    "                    \"gold_result\": str(gold_result),\n",
    "                    \"pred_result\": str(pred_result)\n",
    "                })\n",
    "\n",
    "            total += 1\n",
    "            total_local += 1\n",
    "\n",
    "        except Exception as e:\n",
    "            bad_cases.append({\n",
    "                \"db_id\": db_id,\n",
    "                \"question\": question,\n",
    "                \"gold_query\": gold_query,\n",
    "                \"pred_query\": \"N/A\",\n",
    "                \"error_type\": f\"Exception: {str(e)}\",\n",
    "                \"gold_result\": \"N/A\",\n",
    "                \"pred_result\": \"N/A\"\n",
    "            })\n",
    "            total += 1\n",
    "            total_local += 1\n",
    "            continue\n",
    "\n",
    "    correct_by_db[db_id] = correct_local\n",
    "    total_by_db[db_id] = total_local\n",
    "    print(f\"‚úÖ Accuracy for {db_id}: {correct_local}/{total_local} = {correct_local / total_local:.2%}\")\n",
    "\n",
    "safe_model_name = model_name.replace(\"/\", \"_\")\n",
    "output_filename = f\"bad_cases_{safe_model_name}.json\"\n",
    "\n",
    "with open(output_filename, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(bad_cases, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(\"\\nüìä Summary of Accuracy per Dataset:\")\n",
    "for db_id in correct_by_db:\n",
    "    print(f\" - {db_id}: {correct_by_db[db_id]}/{total_by_db[db_id]} = {correct_by_db[db_id] / total_by_db[db_id]:.2%}\")\n",
    "\n",
    "print(f\"\\nüéØ Final Accuracy: {correct}/{total} = {correct / total:.2%}\")\n",
    "print(f\"Saved bad cases to {output_filename}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
